{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoders\n",
    "\n",
    "## Motivating the Autoencoder Architecture\n",
    "\n",
    "When we talked about feed-forward networks, we discussed how each layer learned progressively more relevant representations of the input. Putting aside the fact that we want to generate these low-dimensional representations in an unsupervised fashion, there are fundamental problems with these approaches in general. Specifically, while the selected layer does contain information from the input, the network has been trained to pay attention to the aspects of the input that are critical to solving the task at hand. As a result, there’s a significant amount of information loss with respect to elements of the input that may be important for other classification tasks, but potentially less important than the one immediately at hand. \n",
    "\n",
    "However, the fundamental intuition here still applies. We define a new network architecture that we call the autoencoder. We first take the input and compress it into a low-dimensional vector. This part of the network is called the encoder because it is responsible for producing the low-dimensional embedding or code. The second part of the network, instead of mapping the embedding to an arbitrary label as we would in a feed-forward network, tries to invert the computation of the first half of the network and reconstruct the original input. This piece is known as the decoder.\n",
    "\n",
    "<img src='images/img4.png'>\n",
    "\n",
    "## Implementing an Autoencoder in Tensorflow\n",
    "\n",
    "The seminal paper “Reducing the dimensionality of data with neural networks,” which describes the autoencoder, was written by Hinton and Salakhutdinov in 2006.1 Their hypothesis was that the nonlinear complexities afforded by a neural model would allow them to capture structure that linear methods, such as PCA, would miss. To demonstrate this point, they ran an experiment on MNIST using both an autoencoder and PCA to reduce the dataset into two-dimensional data points. In this section,  we will recreate their experimental setup to validate this hypothesis and further explore the architecture and properties of feed-forward autoencoders.\n",
    "\n",
    "<img src='images/img5.png'>\n",
    "\n",
    "The setup shown in above figure is built with the same principle, but the twodimensional embedding is now treated as the input, and the network attempts to reconstruct the original image. Because we are essentially applying an inverse operation, we architect the decoder network so that the autoencoder has the shape of an hourglass. The output of the decoder network is a 784-dimensional vector  that can be reconstructed into a 28 × 28 image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x, n_code, phase_train):\n",
    "\n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "\n",
    "        with tf.variable_scope(\"hidden_1\"):\n",
    "            hidden_1 = layer(x, [784, n_encoder_hidden_1], [n_encoder_hidden_1], phase_train)\n",
    "        with tf.variable_scope(\"hidden_2\"):\n",
    "            hidden_2 = layer(hidden_1, [n_encoder_hidden_1, n_encoder_hidden_2], [n_encoder_hidden_2], phase_train)\n",
    "        with tf.variable_scope(\"hidden_3\"):\n",
    "            hidden_3 = layer(hidden_2, [n_encoder_hidden_2, n_encoder_hidden_3], [n_encoder_hidden_3], phase_train)\n",
    "        with tf.variable_scope(\"code\"):\n",
    "            code = layer(hidden_3, [n_encoder_hidden_3, n_code], [n_code], phase_train)\n",
    "    return code\n",
    "\n",
    "def decoder(code,n_code,phase_train):\n",
    "    with tf.variable_scope(\"decoder\"):\n",
    "        with tf.variable_scope(\"hidden_1\"):\n",
    "            hidden_1=layer(code,[n_code,n_decoder_hidden_1],[n_decoder_hidden_1],phase_train)\n",
    "        with tf.variable_scope(\"hidden_2\"):\n",
    "            hidden_2=layer(hidden_1,[n_decoder_hidden_1,n_decoder_hidden_2],[n_decoder_hidden_2],phase_train)\n",
    "        with tf.variable_scope(\"hidden_3\"):\n",
    "            hidden_3=layer(hidden_2,[n_decoder_hidden_2,n_decoder_hidden_3],[n_decoder_hidden_3],phase_train)\n",
    "        with tf.variable_scope(\"output\"):\n",
    "            output=layer(hidden_3,[n_decoder_hidden_3,784],[784],phase_train)\n",
    "        return output\n",
    "    \n",
    "def layer(input,weight_shape, bias_shape, phase_train):\n",
    "    weight_init=tf.random_normal_initializer(stddev=(1.0/weight_shape[0])**0.5)\n",
    "    bias_init=tf.constant_initializer(value=0)\n",
    "    W=tf.get_variable(\"W\",weight_shape,initializer=weight_init)\n",
    "    b=tf.get_variable(\"b\",bias_shape,initializer=bias_init)\n",
    "    logits=tf.matmul(input,W)+b\n",
    "    return tf.nn.sigmoid(layer_batch_norm(logits,weight_shape[1],phase_train))\n",
    "\n",
    "\n",
    "def layer_batch_norm(x,n_out,phase_train):\n",
    "    beta_init=tf.constant_initializer(value=0.0,dtype=tf.float32)\n",
    "    gamma_init=tf.constant_initializer(value=1.0,dtype=tf.float32)\n",
    "    beta=tf.get_variable(\"beta\",[n_out],initializer=beta_init)\n",
    "    gamma=tf.get_variable(\"gamma\",[n_out],initializer=gamma_init)\n",
    "    batch_mean,batch_var=tf.nn.moments(x,[0],name='moments')\n",
    "    ema=tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op=ema.apply([batch_mean,batch_var])\n",
    "    ema_mean,ema_var=ema.average(batch_mean),ema.average(batch_var)\n",
    "    \n",
    "    def mean_var_with_update():\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean),tf.identity(batch_var)\n",
    "    mean,var=control_flow_ops.cond(phase_train,mean_var_with_update,lambda:(ema_mean,ema_var))\n",
    "    normed=tf.nn.batch_norm_with_global_normalization(x,mean,var,beta,gamma,1e-3,True)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to construct a measure (or objective function) that describes how well our model functions. Specifically, we want to measure how close the reconstruction is to the original image. We can measure this simply by computing the distance between the original 784-dimensional input and the reconstructed 784-dimensional output.  More specifically, given an input vector I and a reconstruction O, we’d like to minimize the value of\n",
    "$$ ||I-O|| = \\sqrt{\\sum_i{(I_i-O_i)}^2} $$\n",
    "also known as the L2 norm of the difference between the two vectors. We average this function over the whole minibatch to generate our final objective function. Finally, we’ll train the network using the Adam optimizer, logging a scalar summary of the error incurred at every minibatch using tf.scalar_summary. In TensorFlow, we can concisely express the loss and training operations as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output,x):\n",
    "    with tf.variable_scope(\"training\"):\n",
    "        l2=tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output,x)),1))\n",
    "        train_loss=tf.reduce_mean(l2)\n",
    "        train_summary_op=tf.summary.scalar(\"train_cost\",train_loss)\n",
    "        return train_loss,train_summary_op\n",
    "\n",
    "def training(cost,global_step):\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01,beta1=0.9,beta2=0.999,epsilon=1e-08,use_locking=False,name=\"Adam\")\n",
    "    train_op=optimizer.minimize(cost,global_step=global_step)\n",
    "    return train_op\n",
    "\n",
    "def image_summary(summary_label,tensor):\n",
    "    tensor_reshaped=tf.reshape(tensor,[-1,28,28,1])\n",
    "    return tf.summary.image(summary_label,tensor_reshaped)\n",
    "\n",
    "def evaluate(output,x):\n",
    "    with tf.variable_scope(\"validation\"):\n",
    "        in_im_op=image_summary(\"input_image\",x)\n",
    "        out_im_op=image_summary(\"output_image\",output)\n",
    "        l2=tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output,x,name='val_diff')),1))\n",
    "        val_loss=tf.reduce_mean(l2)\n",
    "        val_summary_op=tf.summary.scalar(\"val_cost\",val_loss)\n",
    "        return val_loss,in_im_op,out_im_op,val_summary_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, all that’s left to do is build the model out of these subcomponents and train the model. A lot of this code is familiar, but it has a couple of additional bells and whistles that are worth covering. First, we have modified our usual code to accept a command-line parameter for determining the number of neurons in our code layer. For example, running $ python autoencoder_mnist.py 2 will instantiate a model with two neurons in the code layer. We also reconfigure the model saver to maintain more snapshots of our model. We’ll be reloading our most effective model later to compare its performance to PCA, so we’d like to be able to have access to many snapshots. We use summary writers to also capture the image summaries we generate at the end of each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch:  0001 cost = 7.999153629\n",
      "Validation loss:  6.6351423\n",
      "Epoch:  0002 cost = 6.537048624\n",
      "Validation loss:  6.391499\n",
      "Epoch:  0003 cost = 6.352392913\n",
      "Validation loss:  6.16795\n",
      "Epoch:  0004 cost = 6.206686269\n",
      "Validation loss:  6.0317855\n",
      "Epoch:  0005 cost = 6.125459082\n",
      "Validation loss:  6.0164623\n",
      "Epoch:  0006 cost = 6.069574726\n",
      "Validation loss:  5.9600644\n",
      "Epoch:  0007 cost = 6.013291869\n",
      "Validation loss:  5.882925\n",
      "Epoch:  0008 cost = 5.982091157\n",
      "Validation loss:  5.878444\n",
      "Epoch:  0009 cost = 5.970386131\n",
      "Validation loss:  5.8715787\n",
      "Epoch:  0010 cost = 5.933869539\n",
      "Validation loss:  5.829715\n",
      "Epoch:  0011 cost = 5.922310389\n",
      "Validation loss:  5.797016\n",
      "Epoch:  0012 cost = 5.895324387\n",
      "Validation loss:  5.816644\n",
      "Epoch:  0013 cost = 5.888214655\n",
      "Validation loss:  5.761907\n",
      "Epoch:  0014 cost = 5.868229993\n",
      "Validation loss:  5.7358966\n",
      "Epoch:  0015 cost = 5.850527970\n",
      "Validation loss:  5.7433686\n",
      "Epoch:  0016 cost = 5.833878949\n",
      "Validation loss:  5.6970663\n",
      "Epoch:  0017 cost = 5.814355894\n",
      "Validation loss:  5.7201166\n",
      "Epoch:  0018 cost = 5.829938494\n",
      "Validation loss:  5.7384434\n",
      "Epoch:  0019 cost = 5.810696881\n",
      "Validation loss:  5.6924605\n",
      "Epoch:  0020 cost = 5.822462273\n",
      "Validation loss:  5.6832805\n",
      "Epoch:  0021 cost = 5.797267981\n",
      "Validation loss:  5.680008\n",
      "Epoch:  0022 cost = 5.783523782\n",
      "Validation loss:  5.6505814\n",
      "Epoch:  0023 cost = 5.778878220\n",
      "Validation loss:  5.6583323\n",
      "Epoch:  0024 cost = 5.790485032\n",
      "Validation loss:  5.654505\n",
      "Epoch:  0025 cost = 5.772678316\n",
      "Validation loss:  5.6565633\n",
      "Epoch:  0026 cost = 5.773525373\n",
      "Validation loss:  5.6673136\n",
      "Epoch:  0027 cost = 5.768769570\n",
      "Validation loss:  5.6569314\n",
      "Epoch:  0028 cost = 5.766715553\n",
      "Validation loss:  5.6399317\n",
      "Epoch:  0029 cost = 5.751771007\n",
      "Validation loss:  5.632902\n",
      "Epoch:  0030 cost = 5.748066619\n",
      "Validation loss:  5.6211257\n",
      "Epoch:  0031 cost = 5.748382202\n",
      "Validation loss:  5.621444\n",
      "Epoch:  0032 cost = 5.748906717\n",
      "Validation loss:  5.632234\n",
      "Epoch:  0033 cost = 5.757380265\n",
      "Validation loss:  5.64144\n",
      "Epoch:  0034 cost = 5.756148415\n",
      "Validation loss:  5.6234\n",
      "Epoch:  0035 cost = 5.762019751\n",
      "Validation loss:  5.6565857\n",
      "Epoch:  0036 cost = 5.748465445\n",
      "Validation loss:  5.632611\n",
      "Epoch:  0037 cost = 5.756518654\n",
      "Validation loss:  5.66411\n",
      "Epoch:  0038 cost = 5.738617594\n",
      "Validation loss:  5.590031\n",
      "Epoch:  0039 cost = 5.713268705\n",
      "Validation loss:  5.594609\n",
      "Epoch:  0040 cost = 5.724305717\n",
      "Validation loss:  5.6221757\n",
      "Epoch:  0041 cost = 5.723832019\n",
      "Validation loss:  5.603128\n",
      "Epoch:  0042 cost = 5.710577767\n",
      "Validation loss:  5.579456\n",
      "Epoch:  0043 cost = 5.716154263\n",
      "Validation loss:  5.591312\n",
      "Epoch:  0044 cost = 5.713226759\n",
      "Validation loss:  5.5905547\n",
      "Epoch:  0045 cost = 5.722550285\n",
      "Validation loss:  5.6213064\n",
      "Epoch:  0046 cost = 5.721937447\n",
      "Validation loss:  5.5754843\n",
      "Epoch:  0047 cost = 5.719160778\n",
      "Validation loss:  5.624754\n",
      "Epoch:  0048 cost = 5.692131582\n",
      "Validation loss:  5.6058693\n",
      "Epoch:  0049 cost = 5.708429254\n",
      "Validation loss:  5.5814056\n",
      "Epoch:  0050 cost = 5.699695883\n",
      "Validation loss:  5.5876503\n",
      "Epoch:  0051 cost = 5.695568132\n",
      "Validation loss:  5.624338\n",
      "Epoch:  0052 cost = 5.684814202\n",
      "Validation loss:  5.578123\n",
      "Epoch:  0053 cost = 5.676971792\n",
      "Validation loss:  5.5935082\n",
      "Epoch:  0054 cost = 5.689773749\n",
      "Validation loss:  5.590015\n",
      "Epoch:  0055 cost = 5.735074848\n",
      "Validation loss:  5.606495\n",
      "Epoch:  0056 cost = 5.709946243\n",
      "Validation loss:  5.5928836\n",
      "Epoch:  0057 cost = 5.689961129\n",
      "Validation loss:  5.627866\n",
      "Epoch:  0058 cost = 5.681907510\n",
      "Validation loss:  5.5965548\n",
      "Epoch:  0059 cost = 5.682170220\n",
      "Validation loss:  5.559364\n",
      "Epoch:  0060 cost = 5.689349156\n",
      "Validation loss:  5.5732093\n",
      "Epoch:  0061 cost = 5.701365945\n",
      "Validation loss:  5.5969176\n",
      "Epoch:  0062 cost = 5.708852595\n",
      "Validation loss:  5.5819283\n",
      "Epoch:  0063 cost = 5.685936384\n",
      "Validation loss:  5.5726857\n",
      "Epoch:  0064 cost = 5.691395023\n",
      "Validation loss:  5.5592384\n",
      "Epoch:  0065 cost = 5.675808056\n",
      "Validation loss:  5.5468335\n",
      "Epoch:  0066 cost = 5.659241604\n",
      "Validation loss:  5.5462456\n",
      "Epoch:  0067 cost = 5.653039804\n",
      "Validation loss:  5.5358076\n",
      "Epoch:  0068 cost = 5.651256397\n",
      "Validation loss:  5.5347943\n",
      "Epoch:  0069 cost = 5.646883018\n",
      "Validation loss:  5.5347037\n",
      "Epoch:  0070 cost = 5.633818613\n",
      "Validation loss:  5.5191\n",
      "Epoch:  0071 cost = 5.642062078\n",
      "Validation loss:  5.5439076\n",
      "Epoch:  0072 cost = 5.629726359\n",
      "Validation loss:  5.498065\n",
      "Epoch:  0073 cost = 5.614808636\n",
      "Validation loss:  5.4965653\n",
      "Epoch:  0074 cost = 5.621133800\n",
      "Validation loss:  5.530639\n",
      "Epoch:  0075 cost = 5.628053232\n",
      "Validation loss:  5.497374\n",
      "Epoch:  0076 cost = 5.615513843\n",
      "Validation loss:  5.5310245\n",
      "Epoch:  0077 cost = 5.617113336\n",
      "Validation loss:  5.514082\n",
      "Epoch:  0078 cost = 5.618258580\n",
      "Validation loss:  5.5166616\n",
      "Epoch:  0079 cost = 5.616327623\n",
      "Validation loss:  5.5185995\n",
      "Epoch:  0080 cost = 5.619374466\n",
      "Validation loss:  5.5188155\n",
      "Epoch:  0081 cost = 5.614000731\n",
      "Validation loss:  5.5070195\n",
      "Epoch:  0082 cost = 5.613556244\n",
      "Validation loss:  5.5278096\n",
      "Epoch:  0083 cost = 5.628572437\n",
      "Validation loss:  5.5516033\n",
      "Epoch:  0084 cost = 5.636379432\n",
      "Validation loss:  5.5286813\n",
      "Epoch:  0085 cost = 5.629954117\n",
      "Validation loss:  5.518021\n",
      "Epoch:  0086 cost = 5.621181329\n",
      "Validation loss:  5.5045695\n",
      "Epoch:  0087 cost = 5.595841302\n",
      "Validation loss:  5.4828205\n",
      "Epoch:  0088 cost = 5.610127850\n",
      "Validation loss:  5.5033607\n",
      "Epoch:  0089 cost = 5.606587281\n",
      "Validation loss:  5.504882\n",
      "Epoch:  0090 cost = 5.624442774\n",
      "Validation loss:  5.538602\n",
      "Epoch:  0091 cost = 5.631169771\n",
      "Validation loss:  5.506778\n",
      "Epoch:  0092 cost = 5.612923913\n",
      "Validation loss:  5.534555\n",
      "Epoch:  0093 cost = 5.608274611\n",
      "Validation loss:  5.47614\n",
      "Epoch:  0094 cost = 5.603653887\n",
      "Validation loss:  5.480495\n",
      "Epoch:  0095 cost = 5.595624377\n",
      "Validation loss:  5.4805303\n",
      "Epoch:  0096 cost = 5.593842832\n",
      "Validation loss:  5.47639\n",
      "Epoch:  0097 cost = 5.594686378\n",
      "Validation loss:  5.505925\n",
      "Epoch:  0098 cost = 5.584299401\n",
      "Validation loss:  5.4786563\n",
      "Epoch:  0099 cost = 5.606281226\n",
      "Validation loss:  5.501797\n",
      "Epoch:  0100 cost = 5.597492703\n",
      "Validation loss:  5.4858994\n",
      "Epoch:  0101 cost = 5.596593891\n",
      "Validation loss:  5.4974337\n",
      "Epoch:  0102 cost = 5.605944296\n",
      "Validation loss:  5.4890213\n",
      "Epoch:  0103 cost = 5.606854708\n",
      "Validation loss:  5.4732084\n",
      "Epoch:  0104 cost = 5.605081263\n",
      "Validation loss:  5.47232\n",
      "Epoch:  0105 cost = 5.595093318\n",
      "Validation loss:  5.4838037\n",
      "Epoch:  0106 cost = 5.590795467\n",
      "Validation loss:  5.485411\n",
      "Epoch:  0107 cost = 5.601369720\n",
      "Validation loss:  5.490388\n",
      "Epoch:  0108 cost = 5.590702549\n",
      "Validation loss:  5.4804373\n",
      "Epoch:  0109 cost = 5.588931037\n",
      "Validation loss:  5.467795\n",
      "Epoch:  0110 cost = 5.597804957\n",
      "Validation loss:  5.4932623\n",
      "Epoch:  0111 cost = 5.603603497\n",
      "Validation loss:  5.490691\n",
      "Epoch:  0112 cost = 5.613006205\n",
      "Validation loss:  5.4896774\n",
      "Epoch:  0113 cost = 5.599708553\n",
      "Validation loss:  5.49077\n",
      "Epoch:  0114 cost = 5.611518652\n",
      "Validation loss:  5.4969807\n",
      "Epoch:  0115 cost = 5.619974251\n",
      "Validation loss:  5.498696\n",
      "Epoch:  0116 cost = 5.618615086\n",
      "Validation loss:  5.5144763\n",
      "Epoch:  0117 cost = 5.705102721\n",
      "Validation loss:  5.554749\n",
      "Epoch:  0118 cost = 5.643079736\n",
      "Validation loss:  5.515575\n",
      "Epoch:  0119 cost = 5.627021373\n",
      "Validation loss:  5.49285\n",
      "Epoch:  0120 cost = 5.619498037\n",
      "Validation loss:  5.482435\n",
      "Epoch:  0121 cost = 5.620276961\n",
      "Validation loss:  5.4896026\n",
      "Epoch:  0122 cost = 5.608984695\n",
      "Validation loss:  5.5182323\n",
      "Epoch:  0123 cost = 5.626899723\n",
      "Validation loss:  5.5018377\n",
      "Epoch:  0124 cost = 5.638879981\n",
      "Validation loss:  5.508951\n",
      "Epoch:  0125 cost = 5.639829422\n",
      "Validation loss:  5.5250354\n",
      "Epoch:  0126 cost = 5.647392968\n",
      "Validation loss:  5.5073657\n",
      "Epoch:  0127 cost = 5.649662508\n",
      "Validation loss:  5.5353494\n",
      "Epoch:  0128 cost = 5.636386537\n",
      "Validation loss:  5.5102787\n",
      "Epoch:  0129 cost = 5.619920493\n",
      "Validation loss:  5.50011\n",
      "Epoch:  0130 cost = 5.619404925\n",
      "Validation loss:  5.5164185\n",
      "Epoch:  0131 cost = 5.600147271\n",
      "Validation loss:  5.4794197\n",
      "Epoch:  0132 cost = 5.592822021\n",
      "Validation loss:  5.482752\n",
      "Epoch:  0133 cost = 5.593119991\n",
      "Validation loss:  5.4610076\n",
      "Epoch:  0134 cost = 5.595733696\n",
      "Validation loss:  5.501154\n",
      "Epoch:  0135 cost = 5.595531692\n",
      "Validation loss:  5.493779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0136 cost = 5.597986068\n",
      "Validation loss:  5.4814205\n",
      "Epoch:  0137 cost = 5.598379676\n",
      "Validation loss:  5.5555706\n",
      "Epoch:  0138 cost = 5.585494450\n",
      "Validation loss:  5.4714937\n",
      "Epoch:  0139 cost = 5.584126611\n",
      "Validation loss:  5.455359\n",
      "Epoch:  0140 cost = 5.572630570\n",
      "Validation loss:  5.4442677\n",
      "Epoch:  0141 cost = 5.577249275\n",
      "Validation loss:  5.4503584\n",
      "Epoch:  0142 cost = 5.576811269\n",
      "Validation loss:  5.446489\n",
      "Epoch:  0143 cost = 5.575583943\n",
      "Validation loss:  5.4643135\n",
      "Epoch:  0144 cost = 5.569939688\n",
      "Validation loss:  5.4523425\n",
      "Epoch:  0145 cost = 5.577859045\n",
      "Validation loss:  5.45386\n",
      "Epoch:  0146 cost = 5.557352098\n",
      "Validation loss:  5.441768\n",
      "Epoch:  0147 cost = 5.558429506\n",
      "Validation loss:  5.445495\n",
      "Epoch:  0148 cost = 5.566612889\n",
      "Validation loss:  5.4554725\n",
      "Epoch:  0149 cost = 5.562831919\n",
      "Validation loss:  5.4692063\n",
      "Epoch:  0150 cost = 5.565977473\n",
      "Validation loss:  5.462494\n",
      "Epoch:  0151 cost = 5.567608116\n",
      "Validation loss:  5.4646244\n",
      "Epoch:  0152 cost = 5.564578681\n",
      "Validation loss:  5.4369273\n",
      "Epoch:  0153 cost = 5.567533950\n",
      "Validation loss:  5.4650173\n",
      "Epoch:  0154 cost = 5.565588492\n",
      "Validation loss:  5.444322\n",
      "Epoch:  0155 cost = 5.562411618\n",
      "Validation loss:  5.4430275\n",
      "Epoch:  0156 cost = 5.563664427\n",
      "Validation loss:  5.444276\n",
      "Epoch:  0157 cost = 5.559194578\n",
      "Validation loss:  5.4551415\n",
      "Epoch:  0158 cost = 5.561596065\n",
      "Validation loss:  5.4686065\n",
      "Epoch:  0159 cost = 5.566107583\n",
      "Validation loss:  5.4493384\n",
      "Epoch:  0160 cost = 5.565821380\n",
      "Validation loss:  5.44774\n",
      "Epoch:  0161 cost = 5.554062300\n",
      "Validation loss:  5.43606\n",
      "Epoch:  0162 cost = 5.573808870\n",
      "Validation loss:  5.4724417\n",
      "Epoch:  0163 cost = 5.572853783\n",
      "Validation loss:  5.4481406\n",
      "Epoch:  0164 cost = 5.584230668\n",
      "Validation loss:  5.446943\n",
      "Epoch:  0165 cost = 5.567179650\n",
      "Validation loss:  5.4454193\n",
      "Epoch:  0166 cost = 5.574972049\n",
      "Validation loss:  5.4624586\n",
      "Epoch:  0167 cost = 5.548437099\n",
      "Validation loss:  5.4477034\n",
      "Epoch:  0168 cost = 5.543290586\n",
      "Validation loss:  5.425093\n",
      "Epoch:  0169 cost = 5.551377791\n",
      "Validation loss:  5.42387\n",
      "Epoch:  0170 cost = 5.553926356\n",
      "Validation loss:  5.438048\n",
      "Epoch:  0171 cost = 5.551696409\n",
      "Validation loss:  5.4356494\n",
      "Epoch:  0172 cost = 5.581372665\n",
      "Validation loss:  5.4755826\n",
      "Epoch:  0173 cost = 5.590805557\n",
      "Validation loss:  5.449072\n",
      "Epoch:  0174 cost = 5.574397651\n",
      "Validation loss:  5.432232\n",
      "Epoch:  0175 cost = 5.561233262\n",
      "Validation loss:  5.4480844\n",
      "Epoch:  0176 cost = 5.552224049\n",
      "Validation loss:  5.441012\n",
      "Epoch:  0177 cost = 5.560125573\n",
      "Validation loss:  5.4344463\n",
      "Epoch:  0178 cost = 5.568517159\n",
      "Validation loss:  5.4492197\n",
      "Epoch:  0179 cost = 5.560861064\n",
      "Validation loss:  5.457925\n",
      "Epoch:  0180 cost = 5.555768000\n",
      "Validation loss:  5.4435587\n",
      "Epoch:  0181 cost = 5.553771442\n",
      "Validation loss:  5.4443564\n",
      "Epoch:  0182 cost = 5.557709983\n",
      "Validation loss:  5.42461\n",
      "Epoch:  0183 cost = 5.542502137\n",
      "Validation loss:  5.4339533\n",
      "Epoch:  0184 cost = 5.531203880\n",
      "Validation loss:  5.4148803\n",
      "Epoch:  0185 cost = 5.537220659\n",
      "Validation loss:  5.42515\n",
      "Epoch:  0186 cost = 5.540027257\n",
      "Validation loss:  5.415285\n",
      "Epoch:  0187 cost = 5.532874524\n",
      "Validation loss:  5.4168487\n",
      "Epoch:  0188 cost = 5.534787473\n",
      "Validation loss:  5.420509\n",
      "Epoch:  0189 cost = 5.531603614\n",
      "Validation loss:  5.436193\n",
      "Epoch:  0190 cost = 5.536339941\n",
      "Validation loss:  5.456638\n",
      "Epoch:  0191 cost = 5.531111059\n",
      "Validation loss:  5.4296656\n",
      "Epoch:  0192 cost = 5.549399556\n",
      "Validation loss:  5.4243035\n",
      "Epoch:  0193 cost = 5.536256122\n",
      "Validation loss:  5.4284697\n",
      "Epoch:  0194 cost = 5.530282868\n",
      "Validation loss:  5.4157662\n",
      "Epoch:  0195 cost = 5.549683590\n",
      "Validation loss:  5.438174\n",
      "Epoch:  0196 cost = 5.545966512\n",
      "Validation loss:  5.4479427\n",
      "Epoch:  0197 cost = 5.551193168\n",
      "Validation loss:  5.4078197\n",
      "Epoch:  0198 cost = 5.551988212\n",
      "Validation loss:  5.436722\n",
      "Epoch:  0199 cost = 5.569964378\n",
      "Validation loss:  5.474794\n",
      "Epoch:  0200 cost = 5.582889996\n",
      "Validation loss:  5.459733\n",
      "Epoch:  0201 cost = 5.571954713\n",
      "Validation loss:  5.4808536\n",
      "Epoch:  0202 cost = 5.586819924\n",
      "Validation loss:  5.4536705\n",
      "Epoch:  0203 cost = 5.572323147\n",
      "Validation loss:  5.4358053\n",
      "Epoch:  0204 cost = 5.558927809\n",
      "Validation loss:  5.4315357\n",
      "Epoch:  0205 cost = 5.561852304\n",
      "Validation loss:  5.4493985\n",
      "Epoch:  0206 cost = 5.588262991\n",
      "Validation loss:  5.439069\n",
      "Epoch:  0207 cost = 5.590522975\n",
      "Validation loss:  5.5001593\n",
      "Epoch:  0208 cost = 5.583927318\n",
      "Validation loss:  5.450768\n",
      "Epoch:  0209 cost = 5.579382355\n",
      "Validation loss:  5.4984508\n",
      "Epoch:  0210 cost = 5.608750946\n",
      "Validation loss:  5.465665\n",
      "Epoch:  0211 cost = 5.592393274\n",
      "Validation loss:  5.4678283\n",
      "Epoch:  0212 cost = 5.589925577\n",
      "Validation loss:  5.457482\n",
      "Epoch:  0213 cost = 5.591423410\n",
      "Validation loss:  5.471024\n",
      "Epoch:  0214 cost = 5.588992929\n",
      "Validation loss:  5.4667273\n",
      "Epoch:  0215 cost = 5.593543258\n",
      "Validation loss:  5.465246\n",
      "Epoch:  0216 cost = 5.573958356\n",
      "Validation loss:  5.465993\n",
      "Epoch:  0217 cost = 5.564271935\n",
      "Validation loss:  5.4487834\n",
      "Epoch:  0218 cost = 5.571568298\n",
      "Validation loss:  5.4556656\n",
      "Epoch:  0219 cost = 5.578481156\n",
      "Validation loss:  5.457128\n",
      "Epoch:  0220 cost = 5.574832430\n",
      "Validation loss:  5.4464154\n",
      "Epoch:  0221 cost = 5.578621225\n",
      "Validation loss:  5.4531884\n",
      "Epoch:  0222 cost = 5.563883789\n",
      "Validation loss:  5.428923\n",
      "Epoch:  0223 cost = 5.557720946\n",
      "Validation loss:  5.4500604\n",
      "Epoch:  0224 cost = 5.556245064\n",
      "Validation loss:  5.426015\n",
      "Epoch:  0225 cost = 5.546020950\n",
      "Validation loss:  5.44129\n",
      "Epoch:  0226 cost = 5.562664430\n",
      "Validation loss:  5.4242563\n",
      "Epoch:  0227 cost = 5.549255820\n",
      "Validation loss:  5.4176273\n",
      "Epoch:  0228 cost = 5.550109305\n",
      "Validation loss:  5.435384\n",
      "Epoch:  0229 cost = 5.544909497\n",
      "Validation loss:  5.432026\n",
      "Epoch:  0230 cost = 5.543593700\n",
      "Validation loss:  5.4653335\n",
      "Epoch:  0231 cost = 5.555461739\n",
      "Validation loss:  5.4266715\n",
      "Epoch:  0232 cost = 5.552766872\n",
      "Validation loss:  5.4291487\n",
      "Epoch:  0233 cost = 5.553248825\n",
      "Validation loss:  5.425218\n",
      "Epoch:  0234 cost = 5.558580362\n",
      "Validation loss:  5.4216447\n",
      "Epoch:  0235 cost = 5.562910668\n",
      "Validation loss:  5.4388947\n",
      "Epoch:  0236 cost = 5.543005264\n",
      "Validation loss:  5.399383\n",
      "Epoch:  0237 cost = 5.534715140\n",
      "Validation loss:  5.4111056\n",
      "Epoch:  0238 cost = 5.526208090\n",
      "Validation loss:  5.402755\n",
      "Epoch:  0239 cost = 5.525948843\n",
      "Validation loss:  5.399562\n",
      "Epoch:  0240 cost = 5.527832454\n",
      "Validation loss:  5.4112663\n",
      "Epoch:  0241 cost = 5.534023318\n",
      "Validation loss:  5.4017253\n",
      "Epoch:  0242 cost = 5.533026253\n",
      "Validation loss:  5.412124\n",
      "Epoch:  0243 cost = 5.529390424\n",
      "Validation loss:  5.4094744\n",
      "Epoch:  0244 cost = 5.523825721\n",
      "Validation loss:  5.409771\n",
      "Epoch:  0245 cost = 5.520528036\n",
      "Validation loss:  5.392819\n",
      "Epoch:  0246 cost = 5.519924290\n",
      "Validation loss:  5.409056\n",
      "Epoch:  0247 cost = 5.526077931\n",
      "Validation loss:  5.395136\n",
      "Epoch:  0248 cost = 5.518838888\n",
      "Validation loss:  5.4134583\n",
      "Epoch:  0249 cost = 5.512976920\n",
      "Validation loss:  5.4022455\n",
      "Epoch:  0250 cost = 5.507412982\n",
      "Validation loss:  5.380291\n",
      "Epoch:  0251 cost = 5.507751389\n",
      "Validation loss:  5.392707\n",
      "Epoch:  0252 cost = 5.507100340\n",
      "Validation loss:  5.3775015\n",
      "Epoch:  0253 cost = 5.513337159\n",
      "Validation loss:  5.397916\n",
      "Epoch:  0254 cost = 5.509038405\n",
      "Validation loss:  5.3919907\n",
      "Epoch:  0255 cost = 5.506644871\n",
      "Validation loss:  5.3737698\n",
      "Epoch:  0256 cost = 5.505557845\n",
      "Validation loss:  5.3624787\n",
      "Epoch:  0257 cost = 5.509935926\n",
      "Validation loss:  5.389629\n",
      "Epoch:  0258 cost = 5.513683269\n",
      "Validation loss:  5.3689947\n",
      "Epoch:  0259 cost = 5.511065891\n",
      "Validation loss:  5.4055204\n",
      "Epoch:  0260 cost = 5.501505091\n",
      "Validation loss:  5.3747296\n",
      "Epoch:  0261 cost = 5.502652010\n",
      "Validation loss:  5.371097\n",
      "Epoch:  0262 cost = 5.507550407\n",
      "Validation loss:  5.390261\n",
      "Epoch:  0263 cost = 5.511507787\n",
      "Validation loss:  5.387764\n",
      "Epoch:  0264 cost = 5.518003544\n",
      "Validation loss:  5.4024587\n",
      "Epoch:  0265 cost = 5.518705871\n",
      "Validation loss:  5.4042015\n",
      "Epoch:  0266 cost = 5.525541851\n",
      "Validation loss:  5.4171367\n",
      "Epoch:  0267 cost = 5.527010326\n",
      "Validation loss:  5.40092\n",
      "Epoch:  0268 cost = 5.533698262\n",
      "Validation loss:  5.404387\n",
      "Epoch:  0269 cost = 5.525874024\n",
      "Validation loss:  5.431418\n",
      "Epoch:  0270 cost = 5.521506884\n",
      "Validation loss:  5.478149\n",
      "Epoch:  0271 cost = 5.526198159\n",
      "Validation loss:  5.417913\n",
      "Epoch:  0272 cost = 5.522164010\n",
      "Validation loss:  5.4138117\n",
      "Epoch:  0273 cost = 5.526467400\n",
      "Validation loss:  5.4046273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0274 cost = 5.527370068\n",
      "Validation loss:  5.437241\n",
      "Epoch:  0275 cost = 5.527399062\n",
      "Validation loss:  5.4014482\n",
      "Epoch:  0276 cost = 5.527395100\n",
      "Validation loss:  5.43152\n",
      "Epoch:  0277 cost = 5.529826906\n",
      "Validation loss:  5.435843\n",
      "Epoch:  0278 cost = 5.513572279\n",
      "Validation loss:  5.395786\n",
      "Epoch:  0279 cost = 5.513888815\n",
      "Validation loss:  5.3820076\n",
      "Epoch:  0280 cost = 5.503813575\n",
      "Validation loss:  5.3845787\n",
      "Epoch:  0281 cost = 5.504328482\n",
      "Validation loss:  5.396221\n",
      "Epoch:  0282 cost = 5.511629189\n",
      "Validation loss:  5.3948307\n",
      "Epoch:  0283 cost = 5.513192485\n",
      "Validation loss:  5.3922215\n",
      "Epoch:  0284 cost = 5.497397471\n",
      "Validation loss:  5.3702273\n",
      "Epoch:  0285 cost = 5.499652390\n",
      "Validation loss:  5.379018\n",
      "Epoch:  0286 cost = 5.523483204\n",
      "Validation loss:  5.4058657\n",
      "Epoch:  0287 cost = 5.526093799\n",
      "Validation loss:  5.388698\n",
      "Epoch:  0288 cost = 5.514292289\n",
      "Validation loss:  5.3971605\n",
      "Epoch:  0289 cost = 5.514167167\n",
      "Validation loss:  5.394954\n",
      "Epoch:  0290 cost = 5.512693546\n",
      "Validation loss:  5.3943257\n",
      "Epoch:  0291 cost = 5.524013999\n",
      "Validation loss:  5.392092\n",
      "Epoch:  0292 cost = 5.512088823\n",
      "Validation loss:  5.3804913\n",
      "Epoch:  0293 cost = 5.520851590\n",
      "Validation loss:  5.38286\n",
      "Epoch:  0294 cost = 5.510684318\n",
      "Validation loss:  5.3822803\n",
      "Epoch:  0295 cost = 5.501986249\n",
      "Validation loss:  5.368148\n",
      "Epoch:  0296 cost = 5.508751444\n",
      "Validation loss:  5.370476\n",
      "Epoch:  0297 cost = 5.504550639\n",
      "Validation loss:  5.3681827\n",
      "Epoch:  0298 cost = 5.511502219\n",
      "Validation loss:  5.380558\n",
      "Epoch:  0299 cost = 5.525896358\n",
      "Validation loss:  5.396074\n",
      "Epoch:  0300 cost = 5.525022415\n",
      "Validation loss:  5.3920956\n",
      "Epoch:  0301 cost = 5.509910296\n",
      "Validation loss:  5.395006\n",
      "Epoch:  0302 cost = 5.507238013\n",
      "Validation loss:  5.37305\n",
      "Epoch:  0303 cost = 5.505180684\n",
      "Validation loss:  5.389065\n",
      "Epoch:  0304 cost = 5.506999707\n",
      "Validation loss:  5.3852115\n",
      "Epoch:  0305 cost = 5.504515154\n",
      "Validation loss:  5.372586\n",
      "Epoch:  0306 cost = 5.501259989\n",
      "Validation loss:  5.3894157\n",
      "Epoch:  0307 cost = 5.508078363\n",
      "Validation loss:  5.3766007\n",
      "Epoch:  0308 cost = 5.500084991\n",
      "Validation loss:  5.3694563\n",
      "Epoch:  0309 cost = 5.501364291\n",
      "Validation loss:  5.363564\n",
      "Epoch:  0310 cost = 5.492757602\n",
      "Validation loss:  5.3624964\n",
      "Epoch:  0311 cost = 5.490040972\n",
      "Validation loss:  5.3618875\n",
      "Epoch:  0312 cost = 5.497039484\n",
      "Validation loss:  5.374147\n",
      "Epoch:  0313 cost = 5.499439098\n",
      "Validation loss:  5.3543544\n",
      "Epoch:  0314 cost = 5.489127412\n",
      "Validation loss:  5.36446\n",
      "Epoch:  0315 cost = 5.494600973\n",
      "Validation loss:  5.3686852\n",
      "Epoch:  0316 cost = 5.480539930\n",
      "Validation loss:  5.381815\n",
      "Epoch:  0317 cost = 5.489467426\n",
      "Validation loss:  5.3543744\n",
      "Epoch:  0318 cost = 5.492598413\n",
      "Validation loss:  5.3852167\n",
      "Epoch:  0319 cost = 5.497421202\n",
      "Validation loss:  5.363821\n",
      "Epoch:  0320 cost = 5.500567896\n",
      "Validation loss:  5.3766975\n",
      "Epoch:  0321 cost = 5.514048827\n",
      "Validation loss:  5.3804917\n",
      "Epoch:  0322 cost = 5.522574033\n",
      "Validation loss:  5.3790846\n",
      "Epoch:  0323 cost = 5.511670174\n",
      "Validation loss:  5.3864603\n",
      "Epoch:  0324 cost = 5.515850326\n",
      "Validation loss:  5.3996267\n",
      "Epoch:  0325 cost = 5.533192648\n",
      "Validation loss:  5.4130383\n",
      "Epoch:  0326 cost = 5.526866755\n",
      "Validation loss:  5.414463\n",
      "Epoch:  0327 cost = 5.528006188\n",
      "Validation loss:  5.406313\n",
      "Epoch:  0328 cost = 5.541457950\n",
      "Validation loss:  5.4104977\n",
      "Epoch:  0329 cost = 5.546639068\n",
      "Validation loss:  5.4112153\n",
      "Epoch:  0330 cost = 5.550761301\n",
      "Validation loss:  5.420096\n",
      "Epoch:  0331 cost = 5.561144195\n",
      "Validation loss:  5.4046426\n",
      "Epoch:  0332 cost = 5.552189226\n",
      "Validation loss:  5.4305806\n",
      "Epoch:  0333 cost = 5.567082311\n",
      "Validation loss:  5.4095345\n",
      "Epoch:  0334 cost = 5.552484685\n",
      "Validation loss:  5.4224787\n",
      "Epoch:  0335 cost = 5.561210827\n",
      "Validation loss:  5.439763\n",
      "Epoch:  0336 cost = 5.548166135\n",
      "Validation loss:  5.419381\n",
      "Epoch:  0337 cost = 5.541441884\n",
      "Validation loss:  5.443596\n",
      "Epoch:  0338 cost = 5.542443482\n",
      "Validation loss:  5.415399\n",
      "Epoch:  0339 cost = 5.534824546\n",
      "Validation loss:  5.404885\n",
      "Epoch:  0340 cost = 5.522251750\n",
      "Validation loss:  5.383202\n",
      "Epoch:  0341 cost = 5.532477235\n",
      "Validation loss:  5.3871818\n",
      "Epoch:  0342 cost = 5.529858931\n",
      "Validation loss:  5.3891687\n",
      "Epoch:  0343 cost = 5.534187002\n",
      "Validation loss:  5.4000764\n",
      "Epoch:  0344 cost = 5.542104137\n",
      "Validation loss:  5.4631047\n",
      "Epoch:  0345 cost = 5.557998040\n",
      "Validation loss:  5.4204617\n",
      "Epoch:  0346 cost = 5.544739470\n",
      "Validation loss:  5.4230585\n",
      "Epoch:  0347 cost = 5.556528630\n",
      "Validation loss:  5.415372\n",
      "Epoch:  0348 cost = 5.552100147\n",
      "Validation loss:  5.428608\n",
      "Epoch:  0349 cost = 5.549795000\n",
      "Validation loss:  5.4310884\n",
      "Epoch:  0350 cost = 5.554026072\n",
      "Validation loss:  5.4191017\n",
      "Epoch:  0351 cost = 5.536867160\n",
      "Validation loss:  5.4071045\n",
      "Epoch:  0352 cost = 5.525904043\n",
      "Validation loss:  5.411145\n",
      "Epoch:  0353 cost = 5.537859084\n",
      "Validation loss:  5.4279366\n",
      "Epoch:  0354 cost = 5.540979849\n",
      "Validation loss:  5.416115\n",
      "Epoch:  0355 cost = 5.545114730\n",
      "Validation loss:  5.4486227\n",
      "Epoch:  0356 cost = 5.534458467\n",
      "Validation loss:  5.394985\n",
      "Epoch:  0357 cost = 5.533847366\n",
      "Validation loss:  5.4311104\n",
      "Epoch:  0358 cost = 5.555177621\n",
      "Validation loss:  5.43008\n",
      "Epoch:  0359 cost = 5.553905371\n",
      "Validation loss:  5.408859\n",
      "Epoch:  0360 cost = 5.538280825\n",
      "Validation loss:  5.405047\n",
      "Epoch:  0361 cost = 5.534901582\n",
      "Validation loss:  5.4272904\n",
      "Epoch:  0362 cost = 5.533707474\n",
      "Validation loss:  5.4114017\n",
      "Epoch:  0363 cost = 5.534188934\n",
      "Validation loss:  5.40641\n",
      "Epoch:  0364 cost = 5.514849719\n",
      "Validation loss:  5.411015\n",
      "Epoch:  0365 cost = 5.521919856\n",
      "Validation loss:  5.3958783\n",
      "Epoch:  0366 cost = 5.521409762\n",
      "Validation loss:  5.402215\n",
      "Epoch:  0367 cost = 5.521630676\n",
      "Validation loss:  5.4033885\n",
      "Epoch:  0368 cost = 5.522368057\n",
      "Validation loss:  5.404251\n",
      "Epoch:  0369 cost = 5.528990896\n",
      "Validation loss:  5.3954678\n",
      "Epoch:  0370 cost = 5.524426555\n",
      "Validation loss:  5.405065\n",
      "Epoch:  0371 cost = 5.516306620\n",
      "Validation loss:  5.4265947\n",
      "Epoch:  0372 cost = 5.520767727\n",
      "Validation loss:  5.417868\n",
      "Epoch:  0373 cost = 5.529377637\n",
      "Validation loss:  5.398741\n",
      "Epoch:  0374 cost = 5.538317936\n",
      "Validation loss:  5.4380546\n",
      "Epoch:  0375 cost = 5.539632922\n",
      "Validation loss:  5.426009\n",
      "Epoch:  0376 cost = 5.537550599\n",
      "Validation loss:  5.425941\n",
      "Epoch:  0377 cost = 5.550237024\n",
      "Validation loss:  5.447234\n",
      "Epoch:  0378 cost = 5.555849170\n",
      "Validation loss:  5.446625\n",
      "Epoch:  0379 cost = 5.568196444\n",
      "Validation loss:  5.4638257\n",
      "Epoch:  0380 cost = 5.558472522\n",
      "Validation loss:  5.434322\n",
      "Epoch:  0381 cost = 5.545021748\n",
      "Validation loss:  5.4292345\n",
      "Epoch:  0382 cost = 5.548551516\n",
      "Validation loss:  5.454561\n",
      "Epoch:  0383 cost = 5.568046348\n",
      "Validation loss:  5.457986\n",
      "Epoch:  0384 cost = 5.594885480\n",
      "Validation loss:  5.466902\n",
      "Epoch:  0385 cost = 5.586854031\n",
      "Validation loss:  5.458133\n",
      "Epoch:  0386 cost = 5.589929453\n",
      "Validation loss:  5.4618664\n",
      "Epoch:  0387 cost = 5.573815911\n",
      "Validation loss:  5.437483\n",
      "Epoch:  0388 cost = 5.563884817\n",
      "Validation loss:  5.4894166\n",
      "Epoch:  0389 cost = 5.586572390\n",
      "Validation loss:  5.471469\n",
      "Epoch:  0390 cost = 5.590691477\n",
      "Validation loss:  5.4887266\n",
      "Epoch:  0391 cost = 5.582701249\n",
      "Validation loss:  5.452872\n",
      "Epoch:  0392 cost = 5.583497050\n",
      "Validation loss:  5.493757\n",
      "Epoch:  0393 cost = 5.609652883\n",
      "Validation loss:  5.472341\n",
      "Epoch:  0394 cost = 5.613331687\n",
      "Validation loss:  5.497622\n",
      "Epoch:  0395 cost = 5.615842353\n",
      "Validation loss:  5.4963474\n",
      "Epoch:  0396 cost = 5.614413819\n",
      "Validation loss:  5.468504\n",
      "Epoch:  0397 cost = 5.570023298\n",
      "Validation loss:  5.435513\n",
      "Epoch:  0398 cost = 5.569749684\n",
      "Validation loss:  5.444249\n",
      "Epoch:  0399 cost = 5.576885685\n",
      "Validation loss:  5.460906\n",
      "Epoch:  0400 cost = 5.582998121\n",
      "Validation loss:  5.484253\n",
      "Epoch:  0401 cost = 5.581717343\n",
      "Validation loss:  5.4649725\n",
      "Epoch:  0402 cost = 5.585012175\n",
      "Validation loss:  5.482332\n",
      "Epoch:  0403 cost = 5.585119409\n",
      "Validation loss:  5.4806957\n",
      "Epoch:  0404 cost = 5.596560959\n",
      "Validation loss:  5.4798193\n",
      "Epoch:  0405 cost = 5.606784508\n",
      "Validation loss:  5.467213\n",
      "Epoch:  0406 cost = 5.600284495\n",
      "Validation loss:  5.4808483\n",
      "Epoch:  0407 cost = 5.606191970\n",
      "Validation loss:  5.4637423\n",
      "Epoch:  0408 cost = 5.591831974\n",
      "Validation loss:  5.4886694\n",
      "Epoch:  0409 cost = 5.578176077\n",
      "Validation loss:  5.4657955\n",
      "Epoch:  0410 cost = 5.555563630\n",
      "Validation loss:  5.4541025\n",
      "Epoch:  0411 cost = 5.559646259\n",
      "Validation loss:  5.4464016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0412 cost = 5.562698414\n",
      "Validation loss:  5.421468\n",
      "Epoch:  0413 cost = 5.571541421\n",
      "Validation loss:  5.4490705\n",
      "Epoch:  0414 cost = 5.572118237\n",
      "Validation loss:  5.4601884\n",
      "Epoch:  0415 cost = 5.589469918\n",
      "Validation loss:  5.477304\n",
      "Epoch:  0416 cost = 5.593666837\n",
      "Validation loss:  5.483932\n",
      "Epoch:  0417 cost = 5.583649304\n",
      "Validation loss:  5.454245\n",
      "Epoch:  0418 cost = 5.585157546\n",
      "Validation loss:  5.4591274\n",
      "Epoch:  0419 cost = 5.563256501\n",
      "Validation loss:  5.449321\n",
      "Epoch:  0420 cost = 5.568848973\n",
      "Validation loss:  5.488666\n",
      "Epoch:  0421 cost = 5.577602117\n",
      "Validation loss:  5.47814\n",
      "Epoch:  0422 cost = 5.580490100\n",
      "Validation loss:  5.4740086\n",
      "Epoch:  0423 cost = 5.563504219\n",
      "Validation loss:  5.468345\n",
      "Epoch:  0424 cost = 5.575361625\n",
      "Validation loss:  5.4620485\n",
      "Epoch:  0425 cost = 5.600217390\n",
      "Validation loss:  5.497427\n",
      "Epoch:  0426 cost = 5.611030358\n",
      "Validation loss:  5.478809\n",
      "Epoch:  0427 cost = 5.627708687\n",
      "Validation loss:  5.5104356\n",
      "Epoch:  0428 cost = 5.616979778\n",
      "Validation loss:  5.500245\n",
      "Epoch:  0429 cost = 5.596869393\n",
      "Validation loss:  5.4930506\n",
      "Epoch:  0430 cost = 5.617596156\n",
      "Validation loss:  5.5003695\n",
      "Epoch:  0431 cost = 5.618615000\n",
      "Validation loss:  5.493358\n",
      "Epoch:  0432 cost = 5.588273823\n",
      "Validation loss:  5.5174065\n",
      "Epoch:  0433 cost = 5.597596991\n",
      "Validation loss:  5.4968386\n",
      "Epoch:  0434 cost = 5.588778885\n",
      "Validation loss:  5.4675527\n",
      "Epoch:  0435 cost = 5.579471927\n",
      "Validation loss:  5.4932485\n",
      "Epoch:  0436 cost = 5.598649897\n",
      "Validation loss:  5.5278454\n",
      "Epoch:  0437 cost = 5.594110274\n",
      "Validation loss:  5.4733543\n",
      "Epoch:  0438 cost = 5.598399804\n",
      "Validation loss:  5.506879\n",
      "Epoch:  0439 cost = 5.598521850\n",
      "Validation loss:  5.5029507\n",
      "Epoch:  0440 cost = 5.612946695\n",
      "Validation loss:  5.493724\n",
      "Epoch:  0441 cost = 5.602022383\n",
      "Validation loss:  5.481174\n",
      "Epoch:  0442 cost = 5.611559262\n",
      "Validation loss:  5.535026\n",
      "Epoch:  0443 cost = 5.616824037\n",
      "Validation loss:  5.5049043\n",
      "Epoch:  0444 cost = 5.625075151\n",
      "Validation loss:  5.5389514\n",
      "Epoch:  0445 cost = 5.606202066\n",
      "Validation loss:  5.488464\n",
      "Epoch:  0446 cost = 5.597006157\n",
      "Validation loss:  5.4797516\n",
      "Epoch:  0447 cost = 5.594711658\n",
      "Validation loss:  5.513049\n",
      "Epoch:  0448 cost = 5.589061826\n",
      "Validation loss:  5.451616\n",
      "Epoch:  0449 cost = 5.569839360\n",
      "Validation loss:  5.4756823\n",
      "Epoch:  0450 cost = 5.570871794\n",
      "Validation loss:  5.4609914\n",
      "Epoch:  0451 cost = 5.584314430\n",
      "Validation loss:  5.460709\n",
      "Epoch:  0452 cost = 5.580675553\n",
      "Validation loss:  5.4803834\n",
      "Epoch:  0453 cost = 5.575931573\n",
      "Validation loss:  5.460115\n",
      "Epoch:  0454 cost = 5.578252103\n",
      "Validation loss:  5.4624677\n",
      "Epoch:  0455 cost = 5.568000525\n",
      "Validation loss:  5.4450974\n",
      "Epoch:  0456 cost = 5.565919546\n",
      "Validation loss:  5.457597\n",
      "Epoch:  0457 cost = 5.573972742\n",
      "Validation loss:  5.4525537\n",
      "Epoch:  0458 cost = 5.574353806\n",
      "Validation loss:  5.466089\n",
      "Epoch:  0459 cost = 5.582943198\n",
      "Validation loss:  5.4481726\n",
      "Epoch:  0460 cost = 5.569437795\n",
      "Validation loss:  5.433558\n",
      "Epoch:  0461 cost = 5.562598099\n",
      "Validation loss:  5.4629173\n",
      "Epoch:  0462 cost = 5.571376657\n",
      "Validation loss:  5.446867\n",
      "Epoch:  0463 cost = 5.562443242\n",
      "Validation loss:  5.449908\n",
      "Epoch:  0464 cost = 5.553398810\n",
      "Validation loss:  5.4320855\n",
      "Epoch:  0465 cost = 5.561007637\n",
      "Validation loss:  5.460247\n",
      "Epoch:  0466 cost = 5.569380982\n",
      "Validation loss:  5.440893\n",
      "Epoch:  0467 cost = 5.550303573\n",
      "Validation loss:  5.4463935\n",
      "Epoch:  0468 cost = 5.549477041\n",
      "Validation loss:  5.426984\n",
      "Epoch:  0469 cost = 5.549777803\n",
      "Validation loss:  5.4405227\n",
      "Epoch:  0470 cost = 5.540491851\n",
      "Validation loss:  5.4431047\n",
      "Epoch:  0471 cost = 5.535753834\n",
      "Validation loss:  5.438813\n",
      "Epoch:  0472 cost = 5.541624406\n",
      "Validation loss:  5.449235\n",
      "Epoch:  0473 cost = 5.545804989\n",
      "Validation loss:  5.4540687\n",
      "Epoch:  0474 cost = 5.545203055\n",
      "Validation loss:  5.437285\n",
      "Epoch:  0475 cost = 5.535105609\n",
      "Validation loss:  5.4399614\n",
      "Epoch:  0476 cost = 5.532237699\n",
      "Validation loss:  5.402118\n",
      "Epoch:  0477 cost = 5.525173348\n",
      "Validation loss:  5.430865\n",
      "Epoch:  0478 cost = 5.519203235\n",
      "Validation loss:  5.407026\n",
      "Epoch:  0479 cost = 5.524137218\n",
      "Validation loss:  5.4004736\n",
      "Epoch:  0480 cost = 5.534910271\n",
      "Validation loss:  5.4233584\n",
      "Epoch:  0481 cost = 5.534953736\n",
      "Validation loss:  5.4220033\n",
      "Epoch:  0482 cost = 5.529331152\n",
      "Validation loss:  5.4001846\n",
      "Epoch:  0483 cost = 5.537241918\n",
      "Validation loss:  5.431654\n",
      "Epoch:  0484 cost = 5.520054765\n",
      "Validation loss:  5.3954444\n",
      "Epoch:  0485 cost = 5.527547668\n",
      "Validation loss:  5.414415\n",
      "Epoch:  0486 cost = 5.532731044\n",
      "Validation loss:  5.4102864\n",
      "Epoch:  0487 cost = 5.545203857\n",
      "Validation loss:  5.462416\n",
      "Epoch:  0488 cost = 5.567431180\n",
      "Validation loss:  5.47477\n",
      "Epoch:  0489 cost = 5.543078182\n",
      "Validation loss:  5.4124045\n",
      "Epoch:  0490 cost = 5.535902026\n",
      "Validation loss:  5.4271626\n",
      "Epoch:  0491 cost = 5.533222162\n",
      "Validation loss:  5.4247956\n",
      "Epoch:  0492 cost = 5.540059806\n",
      "Validation loss:  5.428533\n",
      "Epoch:  0493 cost = 5.558657495\n",
      "Validation loss:  5.4428873\n",
      "Epoch:  0494 cost = 5.559975113\n",
      "Validation loss:  5.415418\n",
      "Epoch:  0495 cost = 5.545691119\n",
      "Validation loss:  5.436069\n",
      "Epoch:  0496 cost = 5.560887556\n",
      "Validation loss:  5.441201\n",
      "Epoch:  0497 cost = 5.552257908\n",
      "Validation loss:  5.4364424\n",
      "Epoch:  0498 cost = 5.546122675\n",
      "Validation loss:  5.4196267\n",
      "Epoch:  0499 cost = 5.547305850\n",
      "Validation loss:  5.4269257\n",
      "Epoch:  0500 cost = 5.556522925\n",
      "Validation loss:  5.447388\n",
      "Epoch:  0501 cost = 5.573112989\n",
      "Validation loss:  5.4416375\n",
      "Epoch:  0502 cost = 5.569808456\n",
      "Validation loss:  5.4306693\n",
      "Epoch:  0503 cost = 5.554609026\n",
      "Validation loss:  5.424944\n",
      "Epoch:  0504 cost = 5.561821458\n",
      "Validation loss:  5.4338474\n",
      "Epoch:  0505 cost = 5.550600322\n",
      "Validation loss:  5.415278\n",
      "Epoch:  0506 cost = 5.553070032\n",
      "Validation loss:  5.417871\n",
      "Epoch:  0507 cost = 5.554638434\n",
      "Validation loss:  5.419045\n",
      "Epoch:  0508 cost = 5.547145878\n",
      "Validation loss:  5.4338303\n",
      "Epoch:  0509 cost = 5.553463932\n",
      "Validation loss:  5.425829\n",
      "Epoch:  0510 cost = 5.559530609\n",
      "Validation loss:  5.436068\n",
      "Epoch:  0511 cost = 5.565801813\n",
      "Validation loss:  5.4197626\n",
      "Epoch:  0512 cost = 5.552342540\n",
      "Validation loss:  5.4092507\n",
      "Epoch:  0513 cost = 5.536047350\n",
      "Validation loss:  5.4193506\n",
      "Epoch:  0514 cost = 5.540249856\n",
      "Validation loss:  5.4445662\n",
      "Epoch:  0515 cost = 5.533532798\n",
      "Validation loss:  5.4256163\n",
      "Epoch:  0516 cost = 5.528143365\n",
      "Validation loss:  5.4083953\n",
      "Epoch:  0517 cost = 5.521337950\n",
      "Validation loss:  5.424305\n",
      "Epoch:  0518 cost = 5.520081144\n",
      "Validation loss:  5.4406157\n",
      "Epoch:  0519 cost = 5.517009886\n",
      "Validation loss:  5.4150815\n",
      "Epoch:  0520 cost = 5.525572958\n",
      "Validation loss:  5.4006953\n",
      "Epoch:  0521 cost = 5.510729778\n",
      "Validation loss:  5.3992906\n",
      "Epoch:  0522 cost = 5.516054314\n",
      "Validation loss:  5.4224277\n",
      "Epoch:  0523 cost = 5.511687641\n",
      "Validation loss:  5.404618\n",
      "Epoch:  0524 cost = 5.506694577\n",
      "Validation loss:  5.4079866\n",
      "Epoch:  0525 cost = 5.506349711\n",
      "Validation loss:  5.3905134\n",
      "Epoch:  0526 cost = 5.514732959\n",
      "Validation loss:  5.3929033\n",
      "Epoch:  0527 cost = 5.508540124\n",
      "Validation loss:  5.4055758\n",
      "Epoch:  0528 cost = 5.517081393\n",
      "Validation loss:  5.4026732\n",
      "Epoch:  0529 cost = 5.509787025\n",
      "Validation loss:  5.3809633\n",
      "Epoch:  0530 cost = 5.510299482\n",
      "Validation loss:  5.393271\n",
      "Epoch:  0531 cost = 5.504702291\n",
      "Validation loss:  5.3958836\n",
      "Epoch:  0532 cost = 5.511171572\n",
      "Validation loss:  5.416269\n",
      "Epoch:  0533 cost = 5.516855198\n",
      "Validation loss:  5.397565\n",
      "Epoch:  0534 cost = 5.525181864\n",
      "Validation loss:  5.4027877\n",
      "Epoch:  0535 cost = 5.513905325\n",
      "Validation loss:  5.3882194\n",
      "Epoch:  0536 cost = 5.515946976\n",
      "Validation loss:  5.4076023\n",
      "Epoch:  0537 cost = 5.523469145\n",
      "Validation loss:  5.416689\n",
      "Epoch:  0538 cost = 5.527379880\n",
      "Validation loss:  5.406151\n",
      "Epoch:  0539 cost = 5.520940089\n",
      "Validation loss:  5.401039\n",
      "Epoch:  0540 cost = 5.517532913\n",
      "Validation loss:  5.3982787\n",
      "Epoch:  0541 cost = 5.519139995\n",
      "Validation loss:  5.409896\n",
      "Epoch:  0542 cost = 5.505499622\n",
      "Validation loss:  5.3974996\n",
      "Epoch:  0543 cost = 5.511442979\n",
      "Validation loss:  5.3874726\n",
      "Epoch:  0544 cost = 5.525622665\n",
      "Validation loss:  5.390553\n",
      "Epoch:  0545 cost = 5.524609911\n",
      "Validation loss:  5.42572\n",
      "Epoch:  0546 cost = 5.526429099\n",
      "Validation loss:  5.395473\n",
      "Epoch:  0547 cost = 5.521886748\n",
      "Validation loss:  5.3952627\n",
      "Epoch:  0548 cost = 5.527379760\n",
      "Validation loss:  5.399008\n",
      "Epoch:  0549 cost = 5.525349783\n",
      "Validation loss:  5.425129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0550 cost = 5.539002511\n",
      "Validation loss:  5.4361086\n",
      "Epoch:  0551 cost = 5.530090549\n",
      "Validation loss:  5.3898163\n",
      "Epoch:  0552 cost = 5.540459162\n",
      "Validation loss:  5.40597\n",
      "Epoch:  0553 cost = 5.532945753\n",
      "Validation loss:  5.4167023\n",
      "Epoch:  0554 cost = 5.525660086\n",
      "Validation loss:  5.40845\n",
      "Epoch:  0555 cost = 5.529677079\n",
      "Validation loss:  5.3952146\n",
      "Epoch:  0556 cost = 5.527012585\n",
      "Validation loss:  5.3872533\n",
      "Epoch:  0557 cost = 5.522904992\n",
      "Validation loss:  5.397342\n",
      "Epoch:  0558 cost = 5.518370466\n",
      "Validation loss:  5.390886\n",
      "Epoch:  0559 cost = 5.522595458\n",
      "Validation loss:  5.4114914\n",
      "Epoch:  0560 cost = 5.519866424\n",
      "Validation loss:  5.3958826\n",
      "Epoch:  0561 cost = 5.528275011\n",
      "Validation loss:  5.3947873\n",
      "Epoch:  0562 cost = 5.516336940\n",
      "Validation loss:  5.4084644\n",
      "Epoch:  0563 cost = 5.522072385\n",
      "Validation loss:  5.394656\n",
      "Epoch:  0564 cost = 5.513227560\n",
      "Validation loss:  5.3995047\n",
      "Epoch:  0565 cost = 5.521970153\n",
      "Validation loss:  5.398073\n",
      "Epoch:  0566 cost = 5.523283607\n",
      "Validation loss:  5.3937335\n",
      "Epoch:  0567 cost = 5.524441265\n",
      "Validation loss:  5.42363\n",
      "Epoch:  0568 cost = 5.522127464\n",
      "Validation loss:  5.402414\n",
      "Epoch:  0569 cost = 5.523895467\n",
      "Validation loss:  5.4046845\n",
      "Epoch:  0570 cost = 5.525632727\n",
      "Validation loss:  5.410892\n",
      "Epoch:  0571 cost = 5.520835910\n",
      "Validation loss:  5.385516\n",
      "Epoch:  0572 cost = 5.539396680\n",
      "Validation loss:  5.440498\n",
      "Epoch:  0573 cost = 5.543786738\n",
      "Validation loss:  5.419812\n",
      "Epoch:  0574 cost = 5.538263436\n",
      "Validation loss:  5.408742\n",
      "Epoch:  0575 cost = 5.549152801\n",
      "Validation loss:  5.4293814\n",
      "Epoch:  0576 cost = 5.527413049\n",
      "Validation loss:  5.4095273\n",
      "Epoch:  0577 cost = 5.539878293\n",
      "Validation loss:  5.4221687\n",
      "Epoch:  0578 cost = 5.529646276\n",
      "Validation loss:  5.415762\n",
      "Epoch:  0579 cost = 5.524850766\n",
      "Validation loss:  5.397709\n",
      "Epoch:  0580 cost = 5.525272872\n",
      "Validation loss:  5.3907113\n",
      "Epoch:  0581 cost = 5.529811022\n",
      "Validation loss:  5.3979187\n",
      "Epoch:  0582 cost = 5.521164848\n",
      "Validation loss:  5.3935018\n",
      "Epoch:  0583 cost = 5.513374827\n",
      "Validation loss:  5.4044037\n",
      "Epoch:  0584 cost = 5.510078836\n",
      "Validation loss:  5.3876486\n",
      "Epoch:  0585 cost = 5.515285952\n",
      "Validation loss:  5.3943853\n",
      "Epoch:  0586 cost = 5.513263297\n",
      "Validation loss:  5.4005203\n",
      "Epoch:  0587 cost = 5.525014659\n",
      "Validation loss:  5.418139\n",
      "Epoch:  0588 cost = 5.543109072\n",
      "Validation loss:  5.44176\n",
      "Epoch:  0589 cost = 5.533898208\n",
      "Validation loss:  5.4080405\n",
      "Epoch:  0590 cost = 5.528104666\n",
      "Validation loss:  5.4181514\n",
      "Epoch:  0591 cost = 5.533142114\n",
      "Validation loss:  5.433856\n",
      "Epoch:  0592 cost = 5.545604199\n",
      "Validation loss:  5.4125996\n",
      "Epoch:  0593 cost = 5.548835508\n",
      "Validation loss:  5.4130807\n",
      "Epoch:  0594 cost = 5.537187617\n",
      "Validation loss:  5.406156\n",
      "Epoch:  0595 cost = 5.531154530\n",
      "Validation loss:  5.4000983\n",
      "Epoch:  0596 cost = 5.523369209\n",
      "Validation loss:  5.38028\n",
      "Epoch:  0597 cost = 5.504559393\n",
      "Validation loss:  5.3831487\n",
      "Epoch:  0598 cost = 5.501737925\n",
      "Validation loss:  5.3728714\n",
      "Epoch:  0599 cost = 5.495967555\n",
      "Validation loss:  5.361807\n",
      "Epoch:  0600 cost = 5.500228942\n",
      "Validation loss:  5.387492\n",
      "Epoch:  0601 cost = 5.516076807\n",
      "Validation loss:  5.4441223\n",
      "Epoch:  0602 cost = 5.543065050\n",
      "Validation loss:  5.401171\n",
      "Epoch:  0603 cost = 5.538918571\n",
      "Validation loss:  5.4220457\n",
      "Epoch:  0604 cost = 5.550486386\n",
      "Validation loss:  5.4027095\n",
      "Epoch:  0605 cost = 5.515483412\n",
      "Validation loss:  5.375499\n",
      "Epoch:  0606 cost = 5.542412718\n",
      "Validation loss:  5.4139576\n",
      "Epoch:  0607 cost = 5.549592742\n",
      "Validation loss:  5.4069486\n",
      "Epoch:  0608 cost = 5.527617849\n",
      "Validation loss:  5.411616\n",
      "Epoch:  0609 cost = 5.530450869\n",
      "Validation loss:  5.411639\n",
      "Epoch:  0610 cost = 5.534490399\n",
      "Validation loss:  5.406519\n",
      "Epoch:  0611 cost = 5.541176167\n",
      "Validation loss:  5.4013577\n",
      "Epoch:  0612 cost = 5.529794669\n",
      "Validation loss:  5.3957195\n",
      "Epoch:  0613 cost = 5.517987567\n",
      "Validation loss:  5.3907704\n",
      "Epoch:  0614 cost = 5.527354195\n",
      "Validation loss:  5.395428\n",
      "Epoch:  0615 cost = 5.525514100\n",
      "Validation loss:  5.3755813\n",
      "Epoch:  0616 cost = 5.512968505\n",
      "Validation loss:  5.3839183\n",
      "Epoch:  0617 cost = 5.513030370\n",
      "Validation loss:  5.394995\n",
      "Epoch:  0618 cost = 5.517175351\n",
      "Validation loss:  5.3920913\n",
      "Epoch:  0619 cost = 5.516764063\n",
      "Validation loss:  5.408146\n",
      "Epoch:  0620 cost = 5.503586740\n",
      "Validation loss:  5.367589\n",
      "Epoch:  0621 cost = 5.488050627\n",
      "Validation loss:  5.356155\n",
      "Epoch:  0622 cost = 5.482950948\n",
      "Validation loss:  5.346583\n",
      "Epoch:  0623 cost = 5.488609139\n",
      "Validation loss:  5.360194\n",
      "Epoch:  0624 cost = 5.492352877\n",
      "Validation loss:  5.3720913\n",
      "Epoch:  0625 cost = 5.511983632\n",
      "Validation loss:  5.3917007\n",
      "Epoch:  0626 cost = 5.505387735\n",
      "Validation loss:  5.3855004\n",
      "Epoch:  0627 cost = 5.505488312\n",
      "Validation loss:  5.372443\n",
      "Epoch:  0628 cost = 5.497476442\n",
      "Validation loss:  5.3717484\n",
      "Epoch:  0629 cost = 5.524235067\n",
      "Validation loss:  5.4060445\n",
      "Epoch:  0630 cost = 5.502788467\n",
      "Validation loss:  5.366267\n",
      "Epoch:  0631 cost = 5.505134185\n",
      "Validation loss:  5.3574405\n",
      "Epoch:  0632 cost = 5.487317492\n",
      "Validation loss:  5.3568397\n",
      "Epoch:  0633 cost = 5.488823633\n",
      "Validation loss:  5.354132\n",
      "Epoch:  0634 cost = 5.493563512\n",
      "Validation loss:  5.3543377\n",
      "Epoch:  0635 cost = 5.504636582\n",
      "Validation loss:  5.38045\n",
      "Epoch:  0636 cost = 5.503840243\n",
      "Validation loss:  5.387524\n",
      "Epoch:  0637 cost = 5.503045601\n",
      "Validation loss:  5.3864627\n",
      "Epoch:  0638 cost = 5.519456952\n",
      "Validation loss:  5.4284253\n",
      "Epoch:  0639 cost = 5.499254531\n",
      "Validation loss:  5.3818736\n",
      "Epoch:  0640 cost = 5.501427778\n",
      "Validation loss:  5.377721\n",
      "Epoch:  0641 cost = 5.509852331\n",
      "Validation loss:  5.404062\n",
      "Epoch:  0642 cost = 5.505625838\n",
      "Validation loss:  5.3840413\n",
      "Epoch:  0643 cost = 5.508170625\n",
      "Validation loss:  5.364283\n",
      "Epoch:  0644 cost = 5.497181741\n",
      "Validation loss:  5.375743\n",
      "Epoch:  0645 cost = 5.499890819\n",
      "Validation loss:  5.373097\n",
      "Epoch:  0646 cost = 5.513647193\n",
      "Validation loss:  5.3907747\n",
      "Epoch:  0647 cost = 5.546011105\n",
      "Validation loss:  5.4062963\n",
      "Epoch:  0648 cost = 5.533550227\n",
      "Validation loss:  5.4089966\n",
      "Epoch:  0649 cost = 5.537283638\n",
      "Validation loss:  5.4277463\n",
      "Epoch:  0650 cost = 5.551199202\n",
      "Validation loss:  5.413542\n",
      "Epoch:  0651 cost = 5.534632322\n",
      "Validation loss:  5.4152155\n",
      "Epoch:  0652 cost = 5.529785610\n",
      "Validation loss:  5.4031496\n",
      "Epoch:  0653 cost = 5.525807379\n",
      "Validation loss:  5.4762373\n",
      "Epoch:  0654 cost = 5.528752702\n",
      "Validation loss:  5.399838\n",
      "Epoch:  0655 cost = 5.517032157\n",
      "Validation loss:  5.405057\n",
      "Epoch:  0656 cost = 5.518023503\n",
      "Validation loss:  5.3748736\n",
      "Epoch:  0657 cost = 5.517720455\n",
      "Validation loss:  5.378769\n",
      "Epoch:  0658 cost = 5.510983181\n",
      "Validation loss:  5.381167\n",
      "Epoch:  0659 cost = 5.500841082\n",
      "Validation loss:  5.3850408\n",
      "Epoch:  0660 cost = 5.498218777\n",
      "Validation loss:  5.3637547\n",
      "Epoch:  0661 cost = 5.485199024\n",
      "Validation loss:  5.3363385\n",
      "Epoch:  0662 cost = 5.474610078\n",
      "Validation loss:  5.359018\n",
      "Epoch:  0663 cost = 5.477037754\n",
      "Validation loss:  5.3368263\n",
      "Epoch:  0664 cost = 5.474370534\n",
      "Validation loss:  5.3507085\n",
      "Epoch:  0665 cost = 5.484051306\n",
      "Validation loss:  5.3688\n",
      "Epoch:  0666 cost = 5.482496606\n",
      "Validation loss:  5.369496\n",
      "Epoch:  0667 cost = 5.482049970\n",
      "Validation loss:  5.342075\n",
      "Epoch:  0668 cost = 5.489936119\n",
      "Validation loss:  5.364386\n",
      "Epoch:  0669 cost = 5.474575501\n",
      "Validation loss:  5.338299\n",
      "Epoch:  0670 cost = 5.473437045\n",
      "Validation loss:  5.34173\n",
      "Epoch:  0671 cost = 5.473689711\n",
      "Validation loss:  5.37728\n",
      "Epoch:  0672 cost = 5.473856123\n",
      "Validation loss:  5.358482\n",
      "Epoch:  0673 cost = 5.469625988\n",
      "Validation loss:  5.3417463\n",
      "Epoch:  0674 cost = 5.470882500\n",
      "Validation loss:  5.3362074\n",
      "Epoch:  0675 cost = 5.472451177\n",
      "Validation loss:  5.3508983\n",
      "Epoch:  0676 cost = 5.470806815\n",
      "Validation loss:  5.3665967\n",
      "Epoch:  0677 cost = 5.471415127\n",
      "Validation loss:  5.370264\n",
      "Epoch:  0678 cost = 5.481743261\n",
      "Validation loss:  5.3630266\n",
      "Epoch:  0679 cost = 5.477670046\n",
      "Validation loss:  5.343342\n",
      "Epoch:  0680 cost = 5.479253895\n",
      "Validation loss:  5.36089\n",
      "Epoch:  0681 cost = 5.476358279\n",
      "Validation loss:  5.355727\n",
      "Epoch:  0682 cost = 5.461597616\n",
      "Validation loss:  5.3341837\n",
      "Epoch:  0683 cost = 5.460743205\n",
      "Validation loss:  5.3252983\n",
      "Epoch:  0684 cost = 5.462614617\n",
      "Validation loss:  5.3408866\n",
      "Epoch:  0685 cost = 5.464661641\n",
      "Validation loss:  5.3560452\n",
      "Epoch:  0686 cost = 5.477203190\n",
      "Validation loss:  5.345594\n",
      "Epoch:  0687 cost = 5.459271729\n",
      "Validation loss:  5.3215003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0688 cost = 5.455474104\n",
      "Validation loss:  5.3233337\n",
      "Epoch:  0689 cost = 5.459098597\n",
      "Validation loss:  5.343059\n",
      "Epoch:  0690 cost = 5.474467553\n",
      "Validation loss:  5.3358\n",
      "Epoch:  0691 cost = 5.458653343\n",
      "Validation loss:  5.345341\n",
      "Epoch:  0692 cost = 5.479589820\n",
      "Validation loss:  5.35022\n",
      "Epoch:  0693 cost = 5.477026122\n",
      "Validation loss:  5.360072\n",
      "Epoch:  0694 cost = 5.495363763\n",
      "Validation loss:  5.362425\n",
      "Epoch:  0695 cost = 5.487142963\n",
      "Validation loss:  5.3606176\n",
      "Epoch:  0696 cost = 5.490068798\n",
      "Validation loss:  5.3753343\n",
      "Epoch:  0697 cost = 5.494787436\n",
      "Validation loss:  5.355015\n",
      "Epoch:  0698 cost = 5.484972690\n",
      "Validation loss:  5.3417807\n",
      "Epoch:  0699 cost = 5.483044049\n",
      "Validation loss:  5.3507037\n",
      "Epoch:  0700 cost = 5.485639000\n",
      "Validation loss:  5.3638697\n",
      "Epoch:  0701 cost = 5.486883867\n",
      "Validation loss:  5.33908\n",
      "Epoch:  0702 cost = 5.485267832\n",
      "Validation loss:  5.355208\n",
      "Epoch:  0703 cost = 5.496616070\n",
      "Validation loss:  5.361781\n",
      "Epoch:  0704 cost = 5.489639239\n",
      "Validation loss:  5.3592496\n",
      "Epoch:  0705 cost = 5.499209220\n",
      "Validation loss:  5.3637924\n",
      "Epoch:  0706 cost = 5.507421843\n",
      "Validation loss:  5.383606\n",
      "Epoch:  0707 cost = 5.511914947\n",
      "Validation loss:  5.381448\n",
      "Epoch:  0708 cost = 5.506018734\n",
      "Validation loss:  5.3898654\n",
      "Epoch:  0709 cost = 5.509762797\n",
      "Validation loss:  5.373798\n",
      "Epoch:  0710 cost = 5.524185638\n",
      "Validation loss:  5.39144\n",
      "Epoch:  0711 cost = 5.540483790\n",
      "Validation loss:  5.4165697\n",
      "Epoch:  0712 cost = 5.533337987\n",
      "Validation loss:  5.3999076\n",
      "Epoch:  0713 cost = 5.545754025\n",
      "Validation loss:  5.44537\n",
      "Epoch:  0714 cost = 5.527002516\n",
      "Validation loss:  5.387846\n",
      "Epoch:  0715 cost = 5.539555984\n",
      "Validation loss:  5.3941765\n",
      "Epoch:  0716 cost = 5.520739451\n",
      "Validation loss:  5.368711\n",
      "Epoch:  0717 cost = 5.511147769\n",
      "Validation loss:  5.369677\n",
      "Epoch:  0718 cost = 5.502523762\n",
      "Validation loss:  5.3745804\n",
      "Epoch:  0719 cost = 5.496466489\n",
      "Validation loss:  5.3636217\n",
      "Epoch:  0720 cost = 5.499403165\n",
      "Validation loss:  5.3740335\n",
      "Epoch:  0721 cost = 5.509330414\n",
      "Validation loss:  5.3751698\n",
      "Epoch:  0722 cost = 5.514996865\n",
      "Validation loss:  5.3992558\n",
      "Epoch:  0723 cost = 5.513525152\n",
      "Validation loss:  5.3770604\n",
      "Epoch:  0724 cost = 5.523803905\n",
      "Validation loss:  5.4008565\n",
      "Epoch:  0725 cost = 5.531209079\n",
      "Validation loss:  5.396176\n",
      "Epoch:  0726 cost = 5.537588941\n",
      "Validation loss:  5.4162846\n",
      "Epoch:  0727 cost = 5.531690588\n",
      "Validation loss:  5.3859096\n",
      "Epoch:  0728 cost = 5.532008320\n",
      "Validation loss:  5.4019885\n",
      "Epoch:  0729 cost = 5.547954379\n",
      "Validation loss:  5.408175\n",
      "Epoch:  0730 cost = 5.548511676\n",
      "Validation loss:  5.402501\n",
      "Epoch:  0731 cost = 5.560629054\n",
      "Validation loss:  5.396758\n",
      "Epoch:  0732 cost = 5.540242916\n",
      "Validation loss:  5.382061\n",
      "Epoch:  0733 cost = 5.537995891\n",
      "Validation loss:  5.395401\n",
      "Epoch:  0734 cost = 5.542243706\n",
      "Validation loss:  5.4200273\n",
      "Epoch:  0735 cost = 5.521731032\n",
      "Validation loss:  5.3780093\n",
      "Epoch:  0736 cost = 5.515998135\n",
      "Validation loss:  5.3742986\n",
      "Epoch:  0737 cost = 5.501931001\n",
      "Validation loss:  5.3685694\n",
      "Epoch:  0738 cost = 5.503089001\n",
      "Validation loss:  5.368367\n",
      "Epoch:  0739 cost = 5.501031762\n",
      "Validation loss:  5.377736\n",
      "Epoch:  0740 cost = 5.502035946\n",
      "Validation loss:  5.364462\n",
      "Epoch:  0741 cost = 5.508484878\n",
      "Validation loss:  5.3842235\n",
      "Epoch:  0742 cost = 5.495887751\n",
      "Validation loss:  5.3606944\n",
      "Epoch:  0743 cost = 5.494073076\n",
      "Validation loss:  5.3890233\n",
      "Epoch:  0744 cost = 5.492223402\n",
      "Validation loss:  5.3574405\n",
      "Epoch:  0745 cost = 5.485045804\n",
      "Validation loss:  5.3497734\n",
      "Epoch:  0746 cost = 5.481023222\n",
      "Validation loss:  5.3440127\n",
      "Epoch:  0747 cost = 5.472516176\n",
      "Validation loss:  5.3640924\n",
      "Epoch:  0748 cost = 5.470462109\n",
      "Validation loss:  5.362911\n",
      "Epoch:  0749 cost = 5.482711664\n",
      "Validation loss:  5.3470874\n",
      "Epoch:  0750 cost = 5.486641029\n",
      "Validation loss:  5.3501906\n",
      "Epoch:  0751 cost = 5.482100697\n",
      "Validation loss:  5.3439217\n",
      "Epoch:  0752 cost = 5.480095582\n",
      "Validation loss:  5.3392124\n",
      "Epoch:  0753 cost = 5.473740596\n",
      "Validation loss:  5.342216\n",
      "Epoch:  0754 cost = 5.479478117\n",
      "Validation loss:  5.3369713\n",
      "Epoch:  0755 cost = 5.480052039\n",
      "Validation loss:  5.351389\n",
      "Epoch:  0756 cost = 5.473864600\n",
      "Validation loss:  5.3347325\n",
      "Epoch:  0757 cost = 5.472652905\n",
      "Validation loss:  5.3501678\n",
      "Epoch:  0758 cost = 5.482561742\n",
      "Validation loss:  5.35214\n",
      "Epoch:  0759 cost = 5.490617012\n",
      "Validation loss:  5.356078\n",
      "Epoch:  0760 cost = 5.482230237\n",
      "Validation loss:  5.342574\n",
      "Epoch:  0761 cost = 5.485646440\n",
      "Validation loss:  5.360781\n",
      "Epoch:  0762 cost = 5.475965070\n",
      "Validation loss:  5.347235\n",
      "Epoch:  0763 cost = 5.491017669\n",
      "Validation loss:  5.378024\n",
      "Epoch:  0764 cost = 5.496513948\n",
      "Validation loss:  5.375896\n",
      "Epoch:  0765 cost = 5.502201924\n",
      "Validation loss:  5.354066\n",
      "Epoch:  0766 cost = 5.494494561\n",
      "Validation loss:  5.3694243\n",
      "Epoch:  0767 cost = 5.502539625\n",
      "Validation loss:  5.3549647\n",
      "Epoch:  0768 cost = 5.486710896\n",
      "Validation loss:  5.363859\n",
      "Epoch:  0769 cost = 5.500262127\n",
      "Validation loss:  5.3665686\n",
      "Epoch:  0770 cost = 5.508074144\n",
      "Validation loss:  5.367048\n",
      "Epoch:  0771 cost = 5.490677281\n",
      "Validation loss:  5.3879514\n",
      "Epoch:  0772 cost = 5.492861483\n",
      "Validation loss:  5.363669\n",
      "Epoch:  0773 cost = 5.475641793\n",
      "Validation loss:  5.34368\n",
      "Epoch:  0774 cost = 5.478515539\n",
      "Validation loss:  5.3313127\n",
      "Epoch:  0775 cost = 5.478167036\n",
      "Validation loss:  5.3634157\n",
      "Epoch:  0776 cost = 5.477111294\n",
      "Validation loss:  5.345376\n",
      "Epoch:  0777 cost = 5.499638068\n",
      "Validation loss:  5.3836484\n",
      "Epoch:  0778 cost = 5.510843414\n",
      "Validation loss:  5.36299\n",
      "Epoch:  0779 cost = 5.521357516\n",
      "Validation loss:  5.429883\n",
      "Epoch:  0780 cost = 5.514710002\n",
      "Validation loss:  5.380681\n",
      "Epoch:  0781 cost = 5.514769491\n",
      "Validation loss:  5.3763843\n",
      "Epoch:  0782 cost = 5.516634277\n",
      "Validation loss:  5.373687\n",
      "Epoch:  0783 cost = 5.521362829\n",
      "Validation loss:  5.377031\n",
      "Epoch:  0784 cost = 5.523121164\n",
      "Validation loss:  5.391507\n",
      "Epoch:  0785 cost = 5.518186229\n",
      "Validation loss:  5.377719\n",
      "Epoch:  0786 cost = 5.514654649\n",
      "Validation loss:  5.383546\n",
      "Epoch:  0787 cost = 5.520941632\n",
      "Validation loss:  5.383793\n",
      "Epoch:  0788 cost = 5.526340147\n",
      "Validation loss:  5.3705235\n",
      "Epoch:  0789 cost = 5.525824567\n",
      "Validation loss:  5.381783\n",
      "Epoch:  0790 cost = 5.537367462\n",
      "Validation loss:  5.384106\n",
      "Epoch:  0791 cost = 5.529583546\n",
      "Validation loss:  5.392917\n",
      "Epoch:  0792 cost = 5.545755490\n",
      "Validation loss:  5.4121127\n",
      "Epoch:  0793 cost = 5.542755703\n",
      "Validation loss:  5.407347\n",
      "Epoch:  0794 cost = 5.536679824\n",
      "Validation loss:  5.409319\n",
      "Epoch:  0795 cost = 5.529562260\n",
      "Validation loss:  5.388136\n",
      "Epoch:  0796 cost = 5.525572212\n",
      "Validation loss:  5.3737955\n",
      "Epoch:  0797 cost = 5.516783971\n",
      "Validation loss:  5.390116\n",
      "Epoch:  0798 cost = 5.505063315\n",
      "Validation loss:  5.3568435\n",
      "Epoch:  0799 cost = 5.498649737\n",
      "Validation loss:  5.365941\n",
      "Epoch:  0800 cost = 5.505313628\n",
      "Validation loss:  5.358296\n",
      "Epoch:  0801 cost = 5.517987138\n",
      "Validation loss:  5.3895035\n",
      "Epoch:  0802 cost = 5.520793082\n",
      "Validation loss:  5.3878617\n",
      "Epoch:  0803 cost = 5.520466691\n",
      "Validation loss:  5.3733954\n",
      "Epoch:  0804 cost = 5.517426091\n",
      "Validation loss:  5.368358\n",
      "Epoch:  0805 cost = 5.519829680\n",
      "Validation loss:  5.377302\n",
      "Epoch:  0806 cost = 5.510964194\n",
      "Validation loss:  5.35639\n",
      "Epoch:  0807 cost = 5.491243204\n",
      "Validation loss:  5.3468394\n",
      "Epoch:  0808 cost = 5.492222704\n",
      "Validation loss:  5.3478723\n",
      "Epoch:  0809 cost = 5.486869346\n",
      "Validation loss:  5.364555\n",
      "Epoch:  0810 cost = 5.480851128\n",
      "Validation loss:  5.346543\n",
      "Epoch:  0811 cost = 5.485298012\n",
      "Validation loss:  5.3866644\n",
      "Epoch:  0812 cost = 5.492674522\n",
      "Validation loss:  5.345737\n",
      "Epoch:  0813 cost = 5.492828903\n",
      "Validation loss:  5.3552976\n",
      "Epoch:  0814 cost = 5.495103315\n",
      "Validation loss:  5.3537188\n",
      "Epoch:  0815 cost = 5.485228526\n",
      "Validation loss:  5.3555946\n",
      "Epoch:  0816 cost = 5.494369076\n",
      "Validation loss:  5.373973\n",
      "Epoch:  0817 cost = 5.507537425\n",
      "Validation loss:  5.381337\n",
      "Epoch:  0818 cost = 5.528415655\n",
      "Validation loss:  5.3875523\n",
      "Epoch:  0819 cost = 5.533176557\n",
      "Validation loss:  5.4220195\n",
      "Epoch:  0820 cost = 5.538743441\n",
      "Validation loss:  5.3981743\n",
      "Epoch:  0821 cost = 5.533444738\n",
      "Validation loss:  5.397484\n",
      "Epoch:  0822 cost = 5.525084907\n",
      "Validation loss:  5.3872313\n",
      "Epoch:  0823 cost = 5.518790853\n",
      "Validation loss:  5.377553\n",
      "Epoch:  0824 cost = 5.511034015\n",
      "Validation loss:  5.3707423\n",
      "Epoch:  0825 cost = 5.505120817\n",
      "Validation loss:  5.3853025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0826 cost = 5.507979580\n",
      "Validation loss:  5.377641\n",
      "Epoch:  0827 cost = 5.512255728\n",
      "Validation loss:  5.380063\n",
      "Epoch:  0828 cost = 5.513360538\n",
      "Validation loss:  5.373489\n",
      "Epoch:  0829 cost = 5.510569992\n",
      "Validation loss:  5.4197164\n",
      "Epoch:  0830 cost = 5.520206678\n",
      "Validation loss:  5.4011736\n",
      "Epoch:  0831 cost = 5.521806694\n",
      "Validation loss:  5.40133\n",
      "Epoch:  0832 cost = 5.511810845\n",
      "Validation loss:  5.373845\n",
      "Epoch:  0833 cost = 5.508045006\n",
      "Validation loss:  5.3781023\n",
      "Epoch:  0834 cost = 5.514959358\n",
      "Validation loss:  5.393273\n",
      "Epoch:  0835 cost = 5.517250887\n",
      "Validation loss:  5.365475\n",
      "Epoch:  0836 cost = 5.502417965\n",
      "Validation loss:  5.372471\n",
      "Epoch:  0837 cost = 5.495907337\n",
      "Validation loss:  5.364214\n",
      "Epoch:  0838 cost = 5.494512628\n",
      "Validation loss:  5.3637533\n",
      "Epoch:  0839 cost = 5.501507345\n",
      "Validation loss:  5.375939\n",
      "Epoch:  0840 cost = 5.495315729\n",
      "Validation loss:  5.350961\n",
      "Epoch:  0841 cost = 5.480537015\n",
      "Validation loss:  5.378355\n",
      "Epoch:  0842 cost = 5.485127133\n",
      "Validation loss:  5.353185\n",
      "Epoch:  0843 cost = 5.483297900\n",
      "Validation loss:  5.3784237\n",
      "Epoch:  0844 cost = 5.492255935\n",
      "Validation loss:  5.3659616\n",
      "Epoch:  0845 cost = 5.484250928\n",
      "Validation loss:  5.3612037\n",
      "Epoch:  0846 cost = 5.491689200\n",
      "Validation loss:  5.3665047\n",
      "Epoch:  0847 cost = 5.489104246\n",
      "Validation loss:  5.368348\n",
      "Epoch:  0848 cost = 5.482936547\n",
      "Validation loss:  5.352923\n",
      "Epoch:  0849 cost = 5.492600611\n",
      "Validation loss:  5.3514276\n",
      "Epoch:  0850 cost = 5.492574116\n",
      "Validation loss:  5.34864\n",
      "Epoch:  0851 cost = 5.487923300\n",
      "Validation loss:  5.3448787\n",
      "Epoch:  0852 cost = 5.482216087\n",
      "Validation loss:  5.331933\n",
      "Epoch:  0853 cost = 5.464601655\n",
      "Validation loss:  5.3206143\n",
      "Epoch:  0854 cost = 5.468099202\n",
      "Validation loss:  5.329428\n",
      "Epoch:  0855 cost = 5.468857275\n",
      "Validation loss:  5.350867\n",
      "Epoch:  0856 cost = 5.469474671\n",
      "Validation loss:  5.336373\n",
      "Epoch:  0857 cost = 5.466090432\n",
      "Validation loss:  5.329518\n",
      "Epoch:  0858 cost = 5.465713440\n",
      "Validation loss:  5.3437405\n",
      "Epoch:  0859 cost = 5.463228336\n",
      "Validation loss:  5.3473716\n",
      "Epoch:  0860 cost = 5.464836008\n",
      "Validation loss:  5.321758\n",
      "Epoch:  0861 cost = 5.454160422\n",
      "Validation loss:  5.330226\n",
      "Epoch:  0862 cost = 5.458001580\n",
      "Validation loss:  5.36279\n",
      "Epoch:  0863 cost = 5.477713907\n",
      "Validation loss:  5.349641\n",
      "Epoch:  0864 cost = 5.481007964\n",
      "Validation loss:  5.3880334\n",
      "Epoch:  0865 cost = 5.488233120\n",
      "Validation loss:  5.3412185\n",
      "Epoch:  0866 cost = 5.474410305\n",
      "Validation loss:  5.333398\n",
      "Epoch:  0867 cost = 5.470804730\n",
      "Validation loss:  5.3398347\n",
      "Epoch:  0868 cost = 5.476845756\n",
      "Validation loss:  5.3424287\n",
      "Epoch:  0869 cost = 5.478636617\n",
      "Validation loss:  5.3332253\n",
      "Epoch:  0870 cost = 5.475394934\n",
      "Validation loss:  5.358197\n",
      "Epoch:  0871 cost = 5.482399536\n",
      "Validation loss:  5.3425345\n",
      "Epoch:  0872 cost = 5.479919488\n",
      "Validation loss:  5.3521895\n",
      "Epoch:  0873 cost = 5.469945934\n",
      "Validation loss:  5.339189\n",
      "Epoch:  0874 cost = 5.482720614\n",
      "Validation loss:  5.366522\n",
      "Epoch:  0875 cost = 5.482976480\n",
      "Validation loss:  5.359905\n",
      "Epoch:  0876 cost = 5.490613461\n",
      "Validation loss:  5.352406\n",
      "Epoch:  0877 cost = 5.484240785\n",
      "Validation loss:  5.340288\n",
      "Epoch:  0878 cost = 5.476839207\n",
      "Validation loss:  5.345042\n",
      "Epoch:  0879 cost = 5.472801339\n",
      "Validation loss:  5.341432\n",
      "Epoch:  0880 cost = 5.468527024\n",
      "Validation loss:  5.3410406\n",
      "Epoch:  0881 cost = 5.475407372\n",
      "Validation loss:  5.368379\n",
      "Epoch:  0882 cost = 5.473595717\n",
      "Validation loss:  5.3730373\n",
      "Epoch:  0883 cost = 5.472417716\n",
      "Validation loss:  5.354054\n",
      "Epoch:  0884 cost = 5.469559663\n",
      "Validation loss:  5.3380427\n",
      "Epoch:  0885 cost = 5.462769534\n",
      "Validation loss:  5.370693\n",
      "Epoch:  0886 cost = 5.479942782\n",
      "Validation loss:  5.37653\n",
      "Epoch:  0887 cost = 5.484405957\n",
      "Validation loss:  5.4141455\n",
      "Epoch:  0888 cost = 5.485426050\n",
      "Validation loss:  5.345048\n",
      "Epoch:  0889 cost = 5.478512042\n",
      "Validation loss:  5.3472047\n",
      "Epoch:  0890 cost = 5.463305394\n",
      "Validation loss:  5.347981\n",
      "Epoch:  0891 cost = 5.459632577\n",
      "Validation loss:  5.347097\n",
      "Epoch:  0892 cost = 5.467145234\n",
      "Validation loss:  5.3572135\n",
      "Epoch:  0893 cost = 5.473776022\n",
      "Validation loss:  5.3369827\n",
      "Epoch:  0894 cost = 5.459797628\n",
      "Validation loss:  5.3303447\n",
      "Epoch:  0895 cost = 5.467360859\n",
      "Validation loss:  5.3397856\n",
      "Epoch:  0896 cost = 5.470528498\n",
      "Validation loss:  5.3531466\n",
      "Epoch:  0897 cost = 5.465605944\n",
      "Validation loss:  5.3295217\n",
      "Epoch:  0898 cost = 5.474833925\n",
      "Validation loss:  5.336671\n",
      "Epoch:  0899 cost = 5.474176369\n",
      "Validation loss:  5.346067\n",
      "Epoch:  0900 cost = 5.467705936\n",
      "Validation loss:  5.3507876\n",
      "Epoch:  0901 cost = 5.478536934\n",
      "Validation loss:  5.360491\n",
      "Epoch:  0902 cost = 5.492717434\n",
      "Validation loss:  5.3525057\n",
      "Epoch:  0903 cost = 5.479478484\n",
      "Validation loss:  5.3480234\n",
      "Epoch:  0904 cost = 5.477477661\n",
      "Validation loss:  5.3765283\n",
      "Epoch:  0905 cost = 5.477822533\n",
      "Validation loss:  5.3528104\n",
      "Epoch:  0906 cost = 5.464411419\n",
      "Validation loss:  5.3313985\n",
      "Epoch:  0907 cost = 5.459692265\n",
      "Validation loss:  5.3239174\n",
      "Epoch:  0908 cost = 5.461898086\n",
      "Validation loss:  5.34596\n",
      "Epoch:  0909 cost = 5.459331114\n",
      "Validation loss:  5.323569\n",
      "Epoch:  0910 cost = 5.451678123\n",
      "Validation loss:  5.328224\n",
      "Epoch:  0911 cost = 5.458485962\n",
      "Validation loss:  5.331233\n",
      "Epoch:  0912 cost = 5.463434473\n",
      "Validation loss:  5.3551025\n",
      "Epoch:  0913 cost = 5.455749846\n",
      "Validation loss:  5.332942\n",
      "Epoch:  0914 cost = 5.460824928\n",
      "Validation loss:  5.3436074\n",
      "Epoch:  0915 cost = 5.461004020\n",
      "Validation loss:  5.3298674\n",
      "Epoch:  0916 cost = 5.449469617\n",
      "Validation loss:  5.3263726\n",
      "Epoch:  0917 cost = 5.452724943\n",
      "Validation loss:  5.323566\n",
      "Epoch:  0918 cost = 5.453254704\n",
      "Validation loss:  5.3353243\n",
      "Epoch:  0919 cost = 5.448649419\n",
      "Validation loss:  5.3233833\n",
      "Epoch:  0920 cost = 5.445578518\n",
      "Validation loss:  5.341682\n",
      "Epoch:  0921 cost = 5.437574322\n",
      "Validation loss:  5.3267255\n",
      "Epoch:  0922 cost = 5.426917403\n",
      "Validation loss:  5.3255258\n",
      "Epoch:  0923 cost = 5.430719278\n",
      "Validation loss:  5.306969\n",
      "Epoch:  0924 cost = 5.431225585\n",
      "Validation loss:  5.3208423\n",
      "Epoch:  0925 cost = 5.428499688\n",
      "Validation loss:  5.3303905\n",
      "Epoch:  0926 cost = 5.427157843\n",
      "Validation loss:  5.300279\n",
      "Epoch:  0927 cost = 5.425498817\n",
      "Validation loss:  5.3241363\n",
      "Epoch:  0928 cost = 5.443639423\n",
      "Validation loss:  5.313053\n",
      "Epoch:  0929 cost = 5.441919140\n",
      "Validation loss:  5.312769\n",
      "Epoch:  0930 cost = 5.437343794\n",
      "Validation loss:  5.3141584\n",
      "Epoch:  0931 cost = 5.442488441\n",
      "Validation loss:  5.3199525\n",
      "Epoch:  0932 cost = 5.435045954\n",
      "Validation loss:  5.324615\n",
      "Epoch:  0933 cost = 5.437495092\n",
      "Validation loss:  5.328452\n",
      "Epoch:  0934 cost = 5.440407823\n",
      "Validation loss:  5.326433\n",
      "Epoch:  0935 cost = 5.442901949\n",
      "Validation loss:  5.29834\n",
      "Epoch:  0936 cost = 5.425100694\n",
      "Validation loss:  5.320453\n",
      "Epoch:  0937 cost = 5.430378136\n",
      "Validation loss:  5.311057\n",
      "Epoch:  0938 cost = 5.441231926\n",
      "Validation loss:  5.3210287\n",
      "Epoch:  0939 cost = 5.433210395\n",
      "Validation loss:  5.3078094\n",
      "Epoch:  0940 cost = 5.438703514\n",
      "Validation loss:  5.3146043\n",
      "Epoch:  0941 cost = 5.439476715\n",
      "Validation loss:  5.326894\n",
      "Epoch:  0942 cost = 5.436628733\n",
      "Validation loss:  5.314057\n",
      "Epoch:  0943 cost = 5.441383853\n",
      "Validation loss:  5.318761\n",
      "Epoch:  0944 cost = 5.436443585\n",
      "Validation loss:  5.3207197\n",
      "Epoch:  0945 cost = 5.437936686\n",
      "Validation loss:  5.318271\n",
      "Epoch:  0946 cost = 5.441347874\n",
      "Validation loss:  5.3189144\n",
      "Epoch:  0947 cost = 5.443682343\n",
      "Validation loss:  5.318466\n",
      "Epoch:  0948 cost = 5.445997173\n",
      "Validation loss:  5.3312745\n",
      "Epoch:  0949 cost = 5.441001574\n",
      "Validation loss:  5.3263407\n",
      "Epoch:  0950 cost = 5.442465060\n",
      "Validation loss:  5.30568\n",
      "Epoch:  0951 cost = 5.446661875\n",
      "Validation loss:  5.3239346\n",
      "Epoch:  0952 cost = 5.447262905\n",
      "Validation loss:  5.3081846\n",
      "Epoch:  0953 cost = 5.442959276\n",
      "Validation loss:  5.320826\n",
      "Epoch:  0954 cost = 5.439381157\n",
      "Validation loss:  5.315309\n",
      "Epoch:  0955 cost = 5.444291462\n",
      "Validation loss:  5.332873\n",
      "Epoch:  0956 cost = 5.443995996\n",
      "Validation loss:  5.3160896\n",
      "Epoch:  0957 cost = 5.441910213\n",
      "Validation loss:  5.320825\n",
      "Epoch:  0958 cost = 5.440423019\n",
      "Validation loss:  5.3237877\n",
      "Epoch:  0959 cost = 5.448234474\n",
      "Validation loss:  5.3359556\n",
      "Epoch:  0960 cost = 5.451725134\n",
      "Validation loss:  5.3365054\n",
      "Epoch:  0961 cost = 5.451929385\n",
      "Validation loss:  5.3197346\n",
      "Epoch:  0962 cost = 5.445855552\n",
      "Validation loss:  5.3182664\n",
      "Epoch:  0963 cost = 5.440617547\n",
      "Validation loss:  5.308826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0964 cost = 5.443313124\n",
      "Validation loss:  5.317585\n",
      "Epoch:  0965 cost = 5.446958086\n",
      "Validation loss:  5.3275347\n",
      "Epoch:  0966 cost = 5.455521709\n",
      "Validation loss:  5.331829\n",
      "Epoch:  0967 cost = 5.455851415\n",
      "Validation loss:  5.338665\n",
      "Epoch:  0968 cost = 5.452307941\n",
      "Validation loss:  5.3407326\n",
      "Epoch:  0969 cost = 5.441920595\n",
      "Validation loss:  5.3241773\n",
      "Epoch:  0970 cost = 5.452166563\n",
      "Validation loss:  5.326715\n",
      "Epoch:  0971 cost = 5.446931054\n",
      "Validation loss:  5.313835\n",
      "Epoch:  0972 cost = 5.455862946\n",
      "Validation loss:  5.3420744\n",
      "Epoch:  0973 cost = 5.468980421\n",
      "Validation loss:  5.3342037\n",
      "Epoch:  0974 cost = 5.460151136\n",
      "Validation loss:  5.3297076\n",
      "Epoch:  0975 cost = 5.466823470\n",
      "Validation loss:  5.340048\n",
      "Epoch:  0976 cost = 5.458830501\n",
      "Validation loss:  5.3269854\n",
      "Epoch:  0977 cost = 5.452529240\n",
      "Validation loss:  5.3259635\n",
      "Epoch:  0978 cost = 5.445494284\n",
      "Validation loss:  5.3084474\n",
      "Epoch:  0979 cost = 5.443872127\n",
      "Validation loss:  5.310445\n",
      "Epoch:  0980 cost = 5.455913763\n",
      "Validation loss:  5.3174243\n",
      "Epoch:  0981 cost = 5.451961279\n",
      "Validation loss:  5.3280416\n",
      "Epoch:  0982 cost = 5.453867217\n",
      "Validation loss:  5.314196\n",
      "Epoch:  0983 cost = 5.454404443\n",
      "Validation loss:  5.336482\n",
      "Epoch:  0984 cost = 5.469537337\n",
      "Validation loss:  5.313304\n",
      "Epoch:  0985 cost = 5.460217535\n",
      "Validation loss:  5.327975\n",
      "Epoch:  0986 cost = 5.469945505\n",
      "Validation loss:  5.335367\n",
      "Epoch:  0987 cost = 5.468809462\n",
      "Validation loss:  5.3308764\n",
      "Epoch:  0988 cost = 5.465582214\n",
      "Validation loss:  5.3267546\n",
      "Epoch:  0989 cost = 5.454780229\n",
      "Validation loss:  5.3144712\n",
      "Epoch:  0990 cost = 5.449860841\n",
      "Validation loss:  5.3138385\n",
      "Epoch:  0991 cost = 5.442196170\n",
      "Validation loss:  5.303149\n",
      "Epoch:  0992 cost = 5.436119041\n",
      "Validation loss:  5.3089747\n",
      "Epoch:  0993 cost = 5.442464973\n",
      "Validation loss:  5.340673\n",
      "Epoch:  0994 cost = 5.447374640\n",
      "Validation loss:  5.3248763\n",
      "Epoch:  0995 cost = 5.449465803\n",
      "Validation loss:  5.315742\n",
      "Epoch:  0996 cost = 5.443254394\n",
      "Validation loss:  5.3310366\n",
      "Epoch:  0997 cost = 5.434775065\n",
      "Validation loss:  5.3034773\n",
      "Epoch:  0998 cost = 5.427952691\n",
      "Validation loss:  5.31491\n",
      "Epoch:  0999 cost = 5.432636807\n",
      "Validation loss:  5.3142147\n",
      "Epoch:  1000 cost = 5.438486399\n",
      "Validation loss:  5.317715\n",
      "Optimization finished!\n",
      "Test Loss:  7.1808767\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_encoder_hidden_1 = 1000\n",
    "n_encoder_hidden_2 = 500\n",
    "n_encoder_hidden_3 = 250\n",
    "n_decoder_hidden_1 = 250\n",
    "n_decoder_hidden_2 = 500\n",
    "n_decoder_hidden_3 = 1000\n",
    "\n",
    "# Parameters\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "n_code=\"1\"\n",
    "\n",
    "mnist=input_data.read_data_sets(\"data/\",one_hot=True)\n",
    "with tf.Graph().as_default():\n",
    "    with tf.variable_scope(\"autoencoder_model\"):\n",
    "        x=tf.placeholder(\"float\",[None,784])\n",
    "        phase_train=tf.placeholder(tf.bool)\n",
    "        code=encoder(x,int(n_code),phase_train)\n",
    "        output=decoder(code,int(n_code),phase_train)\n",
    "        cost,train_summary_op=loss(output,x)\n",
    "        global_step=tf.Variable(0,name='global_step',trainable=False)\n",
    "        train_op=training(cost,global_step=global_step)\n",
    "        eval_op,in_im_op,out_im_op,val_summary_op=evaluate(output,x)\n",
    "        summary_op=tf.summary.merge_all()\n",
    "        saver=tf.train.Saver(max_to_keep=200)\n",
    "        sess=tf.Session()\n",
    "        train_writer=tf.summary.FileWriter(\"mnist_autoencoder_hidden=\"+n_code+\"_logs/\",graph=sess.graph)\n",
    "        val_writer=tf.summary.FileWriter(\"mnist_autoencoder_hidden=\"+n_code+\"_logs/\",graph=sess.graph)\n",
    "        init_op=tf.initialize_all_variables()\n",
    "        sess.run(init_op)\n",
    "        \n",
    "        for epoch in range(training_epochs):\n",
    "            avg_cost=0\n",
    "            total_batch=int(mnist.train.num_examples/batch_size)\n",
    "            #loop over all batchs\n",
    "            for i in range(total_batch):\n",
    "                mbatch_x,mbatch_y=mnist.train.next_batch(batch_size)\n",
    "                # fit training using batch data\n",
    "                _, new_cost, train_summary = sess.run([train_op, cost, train_summary_op], feed_dict={x: mbatch_x, phase_train: True})\n",
    "                train_writer.add_summary(train_summary,sess.run(global_step))\n",
    "                #compute avg loss\n",
    "                avg_cost+=new_cost/total_batch\n",
    "            # Display loss per epoch step\n",
    "            if epoch%display_step==0:\n",
    "                print(\"Epoch: \",'%04d'%(epoch+1),\"cost =\",\"{:.9f}\".format(avg_cost))\n",
    "                train_writer.add_summary(train_summary,sess.run(global_step))\n",
    "                val_images=mnist.validation.images\n",
    "                validation_loss,in_im,out_im,val_summary=sess.run([eval_op,in_im_op,out_im_op,val_summary_op],feed_dict={x:mnist.validation.images,phase_train:True})\n",
    "                val_writer.add_summary(in_im,sess.run(global_step))\n",
    "                val_writer.add_summary(out_im,sess.run(global_step))\n",
    "                val_writer.add_summary(val_summary,sess.run(global_step))\n",
    "                print(\"Validation loss: \",validation_loss)\n",
    "                saver.save(sess,\"mnist_autoencoder_hidden=\"+n_code+\"_logs/model_checkpoint-\"+'%04d'%(epoch+1),global_step=global_step)\n",
    "                \n",
    "        print(\"Optimization finished!\")\n",
    "        \n",
    "        test_loss=sess.run(eval_op,feed_dict={x:mnist.test.images,phase_train:False})\n",
    "        print(\"Test Loss: \",test_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/img6.png'>\n",
    "\n",
    "Thanks to how we’ve namespaced the components of our TensorFlow graph, our model is nicely organized. We can easily click through the components and delve deeper, tracing how data flows up through the various layers of the encoder and through the decoder, how the optimizer reads the output of our training module, and how gradients in turn affect all of the components of the model.\n",
    "\n",
    "We also visualize both the training (after each minibatch) and validation costs (after each epoch), closely monitoring the curves for potential overfitting. The TensorBoard visualizations of the costs over the span of training are shown in Figure above. As we would expect for a successful model, both the training and validation curves decrease until they flatten off asymptotically. After approximately 200 epochs, we attain a validation cost of 4.78. While the curves look promising, it’s difficult to, upon first glance, understand whether we’ve reached a plateau at a “good” cost, or whether our model is still doing a poor job of reconstructing the original inputs\n",
    "\n",
    "<img src='images/img7.png'>\n",
    "\n",
    "To get a sense of what that means, let’s explore the MNIST dataset. We pick an arbitrary image of a 1 from the dataset and call it X. In Figures below, we compare the image to all other images in the dataset. Specifically, for each digit class, we compute the average of the L2 costs, comparing X to each instance of the digit class. As a visual aide, we also include the average of all of the instances for each digit class.\n",
    "\n",
    "### Original Inputs\n",
    "<img src='images/img8.png'>\n",
    "\n",
    "### Generated Output\n",
    "<img src='images/img9.png'>\n",
    "\n",
    "Because we are collecting image summaries, we can confirm this hypothesis directly by inspecting the input images and reconstructions directly. The reconstructions for three randomly chosen samples from the test set are shown in Figure below:\n",
    "\n",
    "### 2200 steps\n",
    "<img src='images/img10.png'>\n",
    "\n",
    "### 13750 steps\n",
    "<img src='images/img11.png'>\n",
    "\n",
    "### 43750 steps\n",
    "<img src='images/img12.png'>\n",
    "\n",
    "Finally, we’ll complete the section by exploring the two-dimensional codes produced by traditional PCA and autoencoders. We’ll want to show that autoencoders produce better visualizations. In particular, we’ll want to show that autoencoders do a much better job of visually separating instances of different digit classes than PCA. We’ll start by quickly covering the code we use to produce two-dimensional PCA codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=decomposition.PCA(n_components=2)\n",
    "pca.fit(mnist.train.images)\n",
    "pca_codes=pca.transform(mnist.test.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first pull up the MNIST dataset. We’ve set the flag one_hot=False because we’d like the labels to be provided as integers instead of one-hot vectors (as a quick reminder, a one-hot vector representing an MNIST label would be a vector of size 10 with the ith component set to one to represent digit i and the rest of the components set to zero). We use the commonly used machine learning library scikit-learn to perform the PCA, setting the n_components=2 flat so that scikit-learn knows to generate two-dimensional codes. We can also reconstruct the original images from the twodimensional codes and visualize the reconstructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pca_recon=pca.inverse_transform(pca_codes[:1])\n",
    "plt.imshow(pca_recon[0].reshape((28,28)),cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
